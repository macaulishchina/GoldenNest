"""
è®¾è®¡é™¢ (Studio) - å·¥å…·æ³¨å†Œè¡¨ä¸æ‰§è¡Œå¼•æ“

ä¸º AI è®¨è®ºæä¾›ä»£ç æ„ŸçŸ¥èƒ½åŠ›:
  - read_file: è¯»å–é¡¹ç›®æ–‡ä»¶å†…å®¹
  - search_text: å…¨æ–‡æœç´¢ (æ”¯æŒæ­£åˆ™)
  - list_directory: åˆ—å‡ºç›®å½•å†…å®¹
  - get_file_tree: è·å–é¡¹ç›®ç›®å½•æ ‘

å®‰å…¨æ²™ç®±:
  - è·¯å¾„é™åˆ¶åœ¨ workspace_path å†… (é˜²æ­¢ ../ é€ƒé€¸å’Œç¬¦å·é“¾æ¥é€ƒé€¸)
  - æ•æ„Ÿæ–‡ä»¶é»‘åå• (.env, *.key ç­‰)
  - æ–‡ä»¶è¯»å–è¡Œæ•°ä¸Šé™ (é»˜è®¤ 500 è¡Œ)
  - æœç´¢ç»“æœæ•°é‡ä¸Šé™ (é»˜è®¤ 50 æ¡)
  - åªè¯»: ä¸æä¾›ä»»ä½•å†™å…¥/åˆ é™¤/æ‰§è¡Œå·¥å…·
"""
import asyncio
import logging
import os
import re
import subprocess
import time
from typing import Any, Callable, Dict, List, Optional, Set, Tuple

logger = logging.getLogger(__name__)

# ==================== æƒé™å®šä¹‰ ====================

TOOL_PERMISSIONS = {
    "read_source",   # è¯»å–æºç æ–‡ä»¶
    "read_config",   # è¯»å–é…ç½®æ–‡ä»¶
    "search",        # å…¨æ–‡æœç´¢
    "tree",          # ç›®å½•æµè§ˆ
}

DEFAULT_PERMISSIONS = set(TOOL_PERMISSIONS)  # é»˜è®¤å…¨éƒ¨å¼€å¯

# ==================== å®‰å…¨é™åˆ¶ ====================

# æ•æ„Ÿæ–‡ä»¶/ç›®å½•é»‘åå•
_SENSITIVE_PATTERNS = {
    # æ–‡ä»¶åç²¾ç¡®åŒ¹é…
    ".env", ".env.local", ".env.production",
    # ç›®å½•
    ".git/objects", ".git/refs", ".git/logs",
    "venv", ".venv", "node_modules", "__pycache__",
    # å®‰å…¨ç›¸å…³
    "id_rsa", "id_ed25519",
}

_SENSITIVE_EXTENSIONS = {
    ".key", ".pem", ".p12", ".pfx", ".jks",
    ".secret", ".credentials",
}

# å…è®¸è¯»å–çš„é…ç½®æ–‡ä»¶ (å³ä½¿åŒ¹é…äº†æ•æ„Ÿæ¨¡å¼)
_CONFIG_ALLOWLIST = {
    "package.json", "tsconfig.json", "vite.config.ts",
    "docker-compose.yml", "Dockerfile", "nginx.conf",
    "requirements.txt", "pyproject.toml", "setup.cfg",
    "CLAUDE.md", "README.md", "TODO.md",
}

# æ–‡ä»¶è¯»å–é™åˆ¶
MAX_READ_LINES = 500
MAX_SEARCH_RESULTS = 50
SEARCH_CONTEXT_LINES = 2
TOOL_TIMEOUT_SECONDS = 10

# ç›®å½•æ ‘é™åˆ¶
MAX_TREE_DEPTH = 4
TREE_SKIP_DIRS = {
    "node_modules", "__pycache__", ".git", ".venv", "venv",
    "dist", ".claude", "studio-data", "data", ".idea", ".vscode",
    ".mypy_cache", ".pytest_cache", ".ruff_cache", "htmlcov",
    ".next", ".nuxt", "build", "target",
}


# ==================== å·¥å…·å®šä¹‰ (OpenAI Function Calling Format) ====================

TOOL_DEFINITIONS: List[Dict[str, Any]] = [
    {
        "type": "function",
        "function": {
            "name": "read_file",
            "description": "è¯»å–é¡¹ç›®ä¸­æŒ‡å®šæ–‡ä»¶çš„å†…å®¹ã€‚å¯ä»¥æŒ‡å®šè¡ŒèŒƒå›´åªè¯»å–éƒ¨åˆ†å†…å®¹ã€‚é€‚åˆæŸ¥çœ‹å…·ä½“çš„ä»£ç å®ç°ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {
                        "type": "string",
                        "description": "ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•çš„æ–‡ä»¶è·¯å¾„ï¼Œä¾‹å¦‚ 'backend/app/games/adventure.py'",
                    },
                    "start_line": {
                        "type": "integer",
                        "description": "èµ·å§‹è¡Œå· (1-based)ï¼Œä¸æŒ‡å®šåˆ™ä»ç¬¬ 1 è¡Œå¼€å§‹",
                    },
                    "end_line": {
                        "type": "integer",
                        "description": "ç»“æŸè¡Œå· (1-based, inclusive)ï¼Œä¸æŒ‡å®šåˆ™è¯»åˆ°æ–‡ä»¶æœ«å°¾ (æœ€å¤š 500 è¡Œ)",
                    },
                },
                "required": ["path"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "search_text",
            "description": "åœ¨é¡¹ç›®æ–‡ä»¶ä¸­æœç´¢æ–‡æœ¬æˆ–æ­£åˆ™è¡¨è¾¾å¼ã€‚è¿”å›åŒ¹é…çš„æ–‡ä»¶ã€è¡Œå·å’Œä¸Šä¸‹æ–‡ã€‚é€‚åˆæŸ¥æ‰¾å‡½æ•°å®šä¹‰ã€å˜é‡å¼•ç”¨ç­‰ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "æœç´¢çš„æ–‡æœ¬æˆ–æ­£åˆ™è¡¨è¾¾å¼",
                    },
                    "is_regex": {
                        "type": "boolean",
                        "description": "æ˜¯å¦ä¸ºæ­£åˆ™è¡¨è¾¾å¼ï¼Œé»˜è®¤ false (ç²¾ç¡®æ–‡æœ¬æœç´¢)",
                        "default": False,
                    },
                    "include_pattern": {
                        "type": "string",
                        "description": "é™åˆ¶æœç´¢çš„æ–‡ä»¶å glob æ¨¡å¼ï¼Œä¾‹å¦‚ '*.py'ã€'*.vue'ã€'*.ts'ã€‚æ³¨æ„: åªæ”¯æŒæ–‡ä»¶ååŒ¹é…ï¼Œä¸æ”¯æŒè·¯å¾„å‰ç¼€",
                    },
                },
                "required": ["query"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "list_directory",
            "description": "åˆ—å‡ºæŒ‡å®šç›®å½•çš„å†…å®¹ï¼ˆæ–‡ä»¶å’Œå­ç›®å½•ï¼‰ã€‚é€‚åˆäº†è§£ç›®å½•ç»“æ„ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {
                        "type": "string",
                        "description": "ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•çš„ç›®å½•è·¯å¾„ï¼Œä¾‹å¦‚ 'backend/app/api'ã€‚ç©ºå­—ç¬¦ä¸²è¡¨ç¤ºé¡¹ç›®æ ¹ç›®å½•ã€‚",
                        "default": "",
                    },
                },
                "required": [],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "get_file_tree",
            "description": "è·å–é¡¹ç›®çš„ç›®å½•æ ‘ç»“æ„ã€‚é€‚åˆäº†è§£é¡¹ç›®æ•´ä½“å¸ƒå±€ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {
                        "type": "string",
                        "description": "å­ç›®å½•è·¯å¾„ (ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•)ï¼Œç©ºå­—ç¬¦ä¸²è¡¨ç¤ºæ•´ä¸ªé¡¹ç›®",
                        "default": "",
                    },
                    "max_depth": {
                        "type": "integer",
                        "description": "ç›®å½•æ ‘æœ€å¤§æ·±åº¦ï¼Œé»˜è®¤ 3",
                        "default": 3,
                    },
                },
                "required": [],
            },
        },
    },
]


def get_tool_definitions(permissions: Optional[Set[str]] = None) -> List[Dict[str, Any]]:
    """
    è·å–å½“å‰å¯ç”¨çš„å·¥å…·å®šä¹‰åˆ—è¡¨ (æ ¹æ®æƒé™è¿‡æ»¤)

    Args:
        permissions: å…è®¸çš„æƒé™é›†åˆï¼ŒNone è¡¨ç¤ºä½¿ç”¨é»˜è®¤æƒé™ (å…¨éƒ¨å¼€å¯)

    Returns:
        OpenAI tools format åˆ—è¡¨
    """
    perms = permissions or DEFAULT_PERMISSIONS
    tools = []

    for tool_def in TOOL_DEFINITIONS:
        name = tool_def["function"]["name"]
        required_perm = _TOOL_PERMISSION_MAP.get(name)
        if required_perm and required_perm.issubset(perms):
            tools.append(tool_def)

    return tools


# å·¥å…·å â†’ æ‰€éœ€æƒé™æ˜ å°„
_TOOL_PERMISSION_MAP: Dict[str, Set[str]] = {
    "read_file": {"read_source"},
    "search_text": {"search"},
    "list_directory": {"tree"},
    "get_file_tree": {"tree"},
}


# ==================== è·¯å¾„å®‰å…¨æ£€æŸ¥ ====================

def _validate_path(workspace: str, rel_path: str) -> Tuple[bool, str, str]:
    """
    éªŒè¯è·¯å¾„å®‰å…¨æ€§

    Returns:
        (is_safe, absolute_path, error_message)
    """
    # è§„èŒƒåŒ–è·¯å¾„
    rel_path = rel_path.strip().lstrip("/")

    # é˜»æ­¢ç©ºè·¯å¾„ç”¨äºæ–‡ä»¶æ“ä½œ
    abs_path = os.path.realpath(os.path.join(workspace, rel_path))

    # æ²™ç®±æ£€æŸ¥: å¿…é¡»åœ¨ workspace å†…
    workspace_real = os.path.realpath(workspace)
    if not abs_path.startswith(workspace_real + os.sep) and abs_path != workspace_real:
        return False, abs_path, f"âš ï¸ è·¯å¾„è¶Šç•Œ: '{rel_path}' ä¸åœ¨é¡¹ç›®ç›®å½•å†…"

    return True, abs_path, ""


def _is_sensitive_file(rel_path: str) -> bool:
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åœ¨æ•æ„Ÿé»‘åå•ä¸­"""
    basename = os.path.basename(rel_path)
    _, ext = os.path.splitext(basename)

    # å…è®¸åˆ—è¡¨ä¼˜å…ˆ
    if basename in _CONFIG_ALLOWLIST:
        return False

    # ç²¾ç¡®æ–‡ä»¶ååŒ¹é…
    if basename in _SENSITIVE_PATTERNS:
        return True

    # æ‰©å±•ååŒ¹é…
    if ext.lower() in _SENSITIVE_EXTENSIONS:
        return True

    # è·¯å¾„ä¸­åŒ…å«æ•æ„Ÿç›®å½•
    path_parts = rel_path.replace("\\", "/").split("/")
    for part in path_parts:
        if part in _SENSITIVE_PATTERNS:
            return True

    return False


# ==================== å·¥å…·æ‰§è¡Œå™¨ ====================

async def execute_tool(
    name: str,
    arguments: Dict[str, Any],
    workspace: str,
    permissions: Optional[Set[str]] = None,
) -> str:
    """
    æ‰§è¡ŒæŒ‡å®šå·¥å…·å¹¶è¿”å›ç»“æœæ–‡æœ¬

    Args:
        name: å·¥å…·åç§°
        arguments: å·¥å…·å‚æ•°
        workspace: å·¥ä½œåŒºæ ¹è·¯å¾„
        permissions: å…è®¸çš„æƒé™é›†åˆ

    Returns:
        å·¥å…·æ‰§è¡Œç»“æœ (çº¯æ–‡æœ¬)
    """
    perms = permissions or DEFAULT_PERMISSIONS

    # æƒé™æ£€æŸ¥
    required_perm = _TOOL_PERMISSION_MAP.get(name)
    if required_perm and not required_perm.issubset(perms):
        return f"âš ï¸ å·¥å…· '{name}' å·²è¢«é¡¹ç›®ç®¡ç†å‘˜ç¦ç”¨"

    # æ‰§è¡Œå·¥å…· (å¸¦è¶…æ—¶)
    executor = _TOOL_EXECUTORS.get(name)
    if not executor:
        return f"âš ï¸ æœªçŸ¥å·¥å…·: '{name}'"

    try:
        result = await asyncio.wait_for(
            executor(arguments, workspace),
            timeout=TOOL_TIMEOUT_SECONDS,
        )
        return result
    except asyncio.TimeoutError:
        return f"âš ï¸ å·¥å…· '{name}' æ‰§è¡Œè¶…æ—¶ ({TOOL_TIMEOUT_SECONDS}s)"
    except Exception as e:
        logger.exception(f"å·¥å…· {name} æ‰§è¡Œå¤±è´¥")
        return f"âš ï¸ å·¥å…·æ‰§è¡Œå¤±è´¥: {str(e)}"


# ==================== å…·ä½“å·¥å…·å®ç° ====================

async def _tool_read_file(args: Dict[str, Any], workspace: str) -> str:
    """è¯»å–æ–‡ä»¶å†…å®¹"""
    path = args.get("path", "")
    start_line = args.get("start_line", 1)
    end_line = args.get("end_line")

    if not path:
        return "âš ï¸ è¯·æŒ‡å®šæ–‡ä»¶è·¯å¾„"

    # è·¯å¾„å®‰å…¨æ£€æŸ¥
    is_safe, abs_path, error = _validate_path(workspace, path)
    if not is_safe:
        return error

    # æ•æ„Ÿæ–‡ä»¶æ£€æŸ¥
    if _is_sensitive_file(path):
        return f"âš ï¸ æ— æ³•è¯»å–æ•æ„Ÿæ–‡ä»¶: '{path}'"

    if not os.path.exists(abs_path):
        return f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: '{path}'"

    if not os.path.isfile(abs_path):
        return f"âš ï¸ '{path}' ä¸æ˜¯æ–‡ä»¶ (å¯èƒ½æ˜¯ç›®å½•ï¼Œè¯·ä½¿ç”¨ list_directory)"

    # æ£€æŸ¥æ–‡ä»¶å¤§å° (è·³è¿‡è¿‡å¤§çš„äºŒè¿›åˆ¶æ–‡ä»¶)
    file_size = os.path.getsize(abs_path)
    if file_size > 1024 * 1024:  # 1MB
        return f"âš ï¸ æ–‡ä»¶è¿‡å¤§ ({file_size / 1024:.0f}KB)ï¼Œè¯·æŒ‡å®šè¡ŒèŒƒå›´è¯»å–"

    try:
        with open(abs_path, "r", encoding="utf-8", errors="replace") as f:
            lines = f.readlines()
    except UnicodeDecodeError:
        return f"âš ï¸ '{path}' æ˜¯äºŒè¿›åˆ¶æ–‡ä»¶ï¼Œæ— æ³•è¯»å–"

    total_lines = len(lines)

    # å¤„ç†è¡ŒèŒƒå›´
    start = max(1, start_line or 1)
    end = min(total_lines, end_line or (start + MAX_READ_LINES - 1))

    # æœ€å¤šè¯»å– MAX_READ_LINES è¡Œ
    if end - start + 1 > MAX_READ_LINES:
        end = start + MAX_READ_LINES - 1

    selected = lines[start - 1:end]
    content = "".join(selected)

    # æ„å»ºç»“æœå¤´ä¿¡æ¯
    header = f"ğŸ“„ {path} (è¡Œ {start}-{end}, å…± {total_lines} è¡Œ)"
    if end < total_lines:
        header += f" [æˆªæ–­: ä½¿ç”¨ start_line/end_line æŸ¥çœ‹æ›´å¤š]"

    return f"{header}\n```\n{content}```"


async def _tool_search_text(args: Dict[str, Any], workspace: str) -> str:
    """å…¨æ–‡æœç´¢"""
    query = args.get("query", "")
    is_regex = args.get("is_regex", False)
    include_pattern = args.get("include_pattern", "")

    if not query:
        return "âš ï¸ è¯·æŒ‡å®šæœç´¢å†…å®¹"

    # æ„å»º grep å‘½ä»¤
    cmd = ["grep", "-rn", "--color=never"]

    if is_regex:
        cmd.append("-E")
    else:
        cmd.append("-F")

    # ä¸Šä¸‹æ–‡è¡Œ
    cmd.extend(["-B", str(SEARCH_CONTEXT_LINES), "-A", str(SEARCH_CONTEXT_LINES)])

    # æœ€å¤§ç»“æœæ•°
    cmd.extend(["-m", str(MAX_SEARCH_RESULTS)])

    # æ’é™¤ç›®å½•
    for skip_dir in TREE_SKIP_DIRS:
        cmd.extend(["--exclude-dir", skip_dir])

    # æ’é™¤æ•æ„Ÿæ–‡ä»¶
    for ext in _SENSITIVE_EXTENSIONS:
        cmd.extend(["--exclude", f"*{ext}"])
    cmd.extend(["--exclude", ".env*"])

    # åŒ…å«æ¨¡å¼ (ä¿®æ­£: grep --include ä¸æ”¯æŒ ** æˆ–è·¯å¾„, åªæ”¯æŒæ–‡ä»¶å glob)
    if include_pattern:
        # å»æ‰è·¯å¾„å‰ç¼€ (å¦‚ **/*.py â†’ *.py, src/**/*.ts â†’ *.ts)
        clean_pattern = include_pattern
        if '/' in clean_pattern:
            clean_pattern = clean_pattern.rsplit('/', 1)[-1]
        if not clean_pattern or clean_pattern == '**':
            clean_pattern = '*'
        cmd.extend(["--include", clean_pattern])

    cmd.append(query)
    cmd.append(".")

    try:
        proc = await asyncio.create_subprocess_exec(
            *cmd,
            cwd=workspace,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
        )
        stdout, stderr = await asyncio.wait_for(proc.communicate(), timeout=TOOL_TIMEOUT_SECONDS)
        output = stdout.decode("utf-8", errors="replace").strip()

        if not output:
            return f"ğŸ” æœªæ‰¾åˆ°åŒ¹é…: '{query}'"

        # æ¸…ç†è·¯å¾„ (å»æ‰ ./ å‰ç¼€)
        output = output.replace("\n./", "\n").lstrip("./")

        # é™åˆ¶è¾“å‡ºé•¿åº¦
        lines = output.split("\n")
        if len(lines) > 200:
            output = "\n".join(lines[:200])
            output += f"\n\n... (ç»“æœè¿‡å¤šï¼Œå·²æˆªæ–­ã€‚è¯·ä½¿ç”¨ include_pattern ç¼©å°èŒƒå›´)"

        pattern_desc = f"æ­£åˆ™ '{query}'" if is_regex else f"'{query}'"
        scope = f" (èŒƒå›´: {include_pattern})" if include_pattern else ""
        return f"ğŸ” æœç´¢ {pattern_desc}{scope}:\n\n{output}"

    except FileNotFoundError:
        # grep ä¸å¯ç”¨ï¼Œé€€å›åˆ° Python å®ç°
        return await _python_search(query, is_regex, include_pattern, workspace)


async def _python_search(
    query: str, is_regex: bool, include_pattern: str, workspace: str,
) -> str:
    """Python å¤‡ç”¨æœç´¢å®ç° (grep ä¸å¯ç”¨æ—¶)"""
    import fnmatch

    if is_regex:
        try:
            pattern = re.compile(query, re.IGNORECASE)
        except re.error as e:
            return f"âš ï¸ æ— æ•ˆçš„æ­£åˆ™è¡¨è¾¾å¼: {e}"
    else:
        pattern = None

    results: List[str] = []
    count = 0

    for root, dirs, files in os.walk(workspace):
        # è·³è¿‡æ’é™¤ç›®å½•
        dirs[:] = [d for d in dirs if d not in TREE_SKIP_DIRS]

        for fname in files:
            if count >= MAX_SEARCH_RESULTS:
                break

            # æ•æ„Ÿæ–‡ä»¶æ£€æŸ¥
            rel_path = os.path.relpath(os.path.join(root, fname), workspace)
            if _is_sensitive_file(rel_path):
                continue

            # include_pattern è¿‡æ»¤
            if include_pattern and not fnmatch.fnmatch(fname, include_pattern):
                continue

            try:
                with open(os.path.join(root, fname), "r", encoding="utf-8", errors="replace") as f:
                    file_lines = f.readlines()
            except Exception:
                continue

            for i, line in enumerate(file_lines):
                if count >= MAX_SEARCH_RESULTS:
                    break

                matched = False
                if pattern:
                    matched = bool(pattern.search(line))
                else:
                    matched = query.lower() in line.lower()

                if matched:
                    count += 1
                    line_num = i + 1
                    # ä¸Šä¸‹æ–‡
                    ctx_start = max(0, i - SEARCH_CONTEXT_LINES)
                    ctx_end = min(len(file_lines), i + SEARCH_CONTEXT_LINES + 1)
                    ctx = ""
                    for j in range(ctx_start, ctx_end):
                        prefix = ">" if j == i else " "
                        ctx += f"{prefix} {j+1}: {file_lines[j]}"
                    results.append(f"{rel_path}:{line_num}\n{ctx}")

    if not results:
        return f"ğŸ” æœªæ‰¾åˆ°åŒ¹é…: '{query}'"

    output = "\n---\n".join(results)
    truncated = f"\n\n... (å·²è¾¾åˆ° {MAX_SEARCH_RESULTS} æ¡ä¸Šé™)" if count >= MAX_SEARCH_RESULTS else ""
    return f"ğŸ” æœç´¢ '{query}' æ‰¾åˆ° {count} ä¸ªåŒ¹é…:\n\n{output}{truncated}"


async def _tool_list_directory(args: Dict[str, Any], workspace: str) -> str:
    """åˆ—å‡ºç›®å½•å†…å®¹"""
    path = args.get("path", "")

    # è·¯å¾„å®‰å…¨æ£€æŸ¥
    is_safe, abs_path, error = _validate_path(workspace, path or ".")
    if not is_safe:
        return error

    if not os.path.exists(abs_path):
        return f"âš ï¸ ç›®å½•ä¸å­˜åœ¨: '{path}'"

    if not os.path.isdir(abs_path):
        return f"âš ï¸ '{path}' ä¸æ˜¯ç›®å½• (è¯·ä½¿ç”¨ read_file è¯»å–æ–‡ä»¶)"

    try:
        entries = sorted(os.listdir(abs_path))
    except PermissionError:
        return f"âš ï¸ æ— æƒè®¿é—®: '{path}'"

    # è¿‡æ»¤éšè—å’Œå¿½ç•¥çš„ç›®å½•
    entries = [e for e in entries if e not in TREE_SKIP_DIRS and not e.startswith("__pycache__")]

    dirs = []
    files = []
    for entry in entries:
        full = os.path.join(abs_path, entry)
        if os.path.isdir(full):
            # è®¡ç®—å­é¡¹æ•°é‡
            try:
                sub_count = len(os.listdir(full))
            except Exception:
                sub_count = 0
            dirs.append(f"ğŸ“ {entry}/ ({sub_count} items)")
        else:
            size = os.path.getsize(full)
            size_str = f"{size}B" if size < 1024 else f"{size / 1024:.1f}KB" if size < 1048576 else f"{size / 1048576:.1f}MB"
            files.append(f"ğŸ“„ {entry} ({size_str})")

    display_path = path or "."
    result = f"ğŸ“‚ {display_path}/\n"
    result += "\n".join(dirs + files)

    if not dirs and not files:
        result += "(ç©ºç›®å½•)"

    return result


async def _tool_get_file_tree(args: Dict[str, Any], workspace: str) -> str:
    """è·å–ç›®å½•æ ‘"""
    path = args.get("path", "")
    max_depth = min(args.get("max_depth", 3), MAX_TREE_DEPTH)

    # è·¯å¾„å®‰å…¨æ£€æŸ¥
    target = os.path.join(workspace, path) if path else workspace
    is_safe, abs_path, error = _validate_path(workspace, path or ".")
    if not is_safe:
        return error

    if not os.path.exists(abs_path):
        return f"âš ï¸ è·¯å¾„ä¸å­˜åœ¨: '{path}'"

    if not os.path.isdir(abs_path):
        return f"âš ï¸ '{path}' ä¸æ˜¯ç›®å½•"

    tree = _build_tree(abs_path, max_depth)
    display_path = path or "."
    return f"ğŸŒ³ {display_path}/ ç›®å½•æ ‘ (æ·±åº¦: {max_depth}):\n\n{tree}"


def _build_tree(path: str, max_depth: int, prefix: str = "", depth: int = 0) -> str:
    """é€’å½’æ„å»ºç›®å½•æ ‘"""
    if depth >= max_depth:
        return ""

    try:
        entries = sorted(os.listdir(path))
    except PermissionError:
        return f"{prefix}(æ— æƒé™è®¿é—®)\n"

    # è¿‡æ»¤
    entries = [e for e in entries if e not in TREE_SKIP_DIRS and not e.startswith(".")]

    lines = []
    for i, entry in enumerate(entries):
        is_last = i == len(entries) - 1
        connector = "â””â”€â”€ " if is_last else "â”œâ”€â”€ "
        full_path = os.path.join(path, entry)

        if os.path.isdir(full_path):
            lines.append(f"{prefix}{connector}{entry}/")
            extension = "    " if is_last else "â”‚   "
            subtree = _build_tree(full_path, max_depth, prefix + extension, depth + 1)
            if subtree:
                lines.append(subtree)
        else:
            lines.append(f"{prefix}{connector}{entry}")

    return "\n".join(lines)


# å·¥å…·æ‰§è¡Œå™¨æ˜ å°„
_TOOL_EXECUTORS: Dict[str, Callable] = {
    "read_file": _tool_read_file,
    "search_text": _tool_search_text,
    "list_directory": _tool_list_directory,
    "get_file_tree": _tool_get_file_tree,
}
