"""
è®¾è®¡é™¢ (Studio) - å·¥å…·æ³¨å†Œè¡¨ä¸æ‰§è¡Œå¼•æ“

ä¸º AI è®¨è®ºæä¾›ä»£ç æ„ŸçŸ¥èƒ½åŠ›:
  - read_file: è¯»å–é¡¹ç›®æ–‡ä»¶å†…å®¹
  - search_text: å…¨æ–‡æœç´¢ (æ”¯æŒæ­£åˆ™)
  - list_directory: åˆ—å‡ºç›®å½•å†…å®¹
  - get_file_tree: è·å–é¡¹ç›®ç›®å½•æ ‘

å®‰å…¨æ²™ç®±:
  - è·¯å¾„é™åˆ¶åœ¨ workspace_path å†… (é˜²æ­¢ ../ é€ƒé€¸å’Œç¬¦å·é“¾æ¥é€ƒé€¸)
  - æ•æ„Ÿæ–‡ä»¶é»‘åå• (.env, *.key ç­‰)
  - æ–‡ä»¶è¯»å–è¡Œæ•°ä¸Šé™ (é»˜è®¤ 500 è¡Œ)
  - æœç´¢ç»“æœæ•°é‡ä¸Šé™ (é»˜è®¤ 50 æ¡)
  - åªè¯»: ä¸æä¾›ä»»ä½•å†™å…¥/åˆ é™¤/æ‰§è¡Œå·¥å…·
"""
import asyncio
import logging
import os
import re
import subprocess
import time
from typing import Any, Callable, Dict, List, Optional, Set, Tuple

logger = logging.getLogger(__name__)

# ==================== æƒé™å®šä¹‰ ====================

TOOL_PERMISSIONS = {
    "ask_user",      # å‘ç”¨æˆ·æé—®æ¾„æ¸…
    "read_source",   # è¯»å–æºç æ–‡ä»¶
    "read_config",   # è¯»å–é…ç½®æ–‡ä»¶
    "search",        # å…¨æ–‡æœç´¢
    "tree",          # ç›®å½•æµè§ˆ
    "execute_readonly_command",  # æ‰§è¡Œåªè¯»å‘½ä»¤ (git log/diff, ls, cat, etc.)
    "execute_command",           # æ‰§è¡Œä»»æ„å‘½ä»¤ (éœ€æ˜¾å¼æˆæƒ)
}

DEFAULT_PERMISSIONS = set(TOOL_PERMISSIONS) - {"execute_command"}  # é»˜è®¤ä¸å¼€æ”¾å†™å‘½ä»¤

# ==================== å®‰å…¨é™åˆ¶ ====================

# æ•æ„Ÿæ–‡ä»¶/ç›®å½•é»‘åå•
_SENSITIVE_PATTERNS = {
    # æ–‡ä»¶åç²¾ç¡®åŒ¹é…
    ".env", ".env.local", ".env.production",
    # ç›®å½•
    ".git/objects", ".git/refs", ".git/logs",
    "venv", ".venv", "node_modules", "__pycache__",
    # å®‰å…¨ç›¸å…³
    "id_rsa", "id_ed25519",
}

_SENSITIVE_EXTENSIONS = {
    ".key", ".pem", ".p12", ".pfx", ".jks",
    ".secret", ".credentials",
}

# å…è®¸è¯»å–çš„é…ç½®æ–‡ä»¶ (å³ä½¿åŒ¹é…äº†æ•æ„Ÿæ¨¡å¼)
_CONFIG_ALLOWLIST = {
    "package.json", "tsconfig.json", "vite.config.ts",
    "docker-compose.yml", "Dockerfile", "nginx.conf",
    "requirements.txt", "pyproject.toml", "setup.cfg",
    "CLAUDE.md", "README.md", "TODO.md",
}

# æ–‡ä»¶è¯»å–é™åˆ¶
MAX_READ_LINES = 200
MAX_SEARCH_RESULTS = 30
SEARCH_CONTEXT_LINES = 1
TOOL_TIMEOUT_SECONDS = 10

# ç›®å½•æ ‘é™åˆ¶
MAX_TREE_DEPTH = 4
TREE_SKIP_DIRS = {
    "node_modules", "__pycache__", ".git", ".venv", "venv",
    "dist", ".claude", "studio-data", "data", ".idea", ".vscode",
    ".mypy_cache", ".pytest_cache", ".ruff_cache", "htmlcov",
    ".next", ".nuxt", "build", "target",
}


# ==================== å·¥å…·å®šä¹‰ (OpenAI Function Calling Format) ====================

TOOL_DEFINITIONS: List[Dict[str, Any]] = [
    {
        "type": "function",
        "function": {
            "name": "read_file",
            "description": (
                "è¯»å–é¡¹ç›®ä¸­çš„æ–‡ä»¶å†…å®¹ã€‚æ”¯æŒæŒ‡å®šèµ·å§‹è¡Œå·æ¥ç²¾ç¡®è¯»å–æ„Ÿå…´è¶£çš„ç‰‡æ®µï¼Œ"
                "ä¸å¿…æ¯æ¬¡ä»å¤´è¯»å–æ•´ä¸ªæ–‡ä»¶ã€‚æ¨èç­–ç•¥ï¼šå…ˆç”¨ search_text å®šä½è¡Œå·ï¼Œ"
                "å†ç”¨ start_line è·³è½¬åˆ°ç›®æ ‡ä½ç½®è¯»å–ã€‚å•æ¬¡æœ€å¤šè¿”å› 200 è¡Œã€‚"
                "å°æ–‡ä»¶ï¼ˆ<200è¡Œï¼‰ç›´æ¥ä¸€æ¬¡è¯»å®Œï¼Œä¸è¦æ‹†åˆ†ã€‚"
            ),
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {
                        "type": "string",
                        "description": "ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•çš„æ–‡ä»¶è·¯å¾„ï¼Œä¾‹å¦‚ 'backend/app/games/adventure.py'",
                    },
                    "start_line": {
                        "type": "integer",
                        "description": (
                            "èµ·å§‹è¡Œå· (1-based)ï¼Œé»˜è®¤ä»ç¬¬ 1 è¡Œå¼€å§‹ã€‚"
                            "é…åˆ search_text è¿”å›çš„è¡Œå·ï¼Œå¯ç›´æ¥è·³åˆ°æ„Ÿå…´è¶£çš„ä»£ç ä½ç½®"
                        ),
                    },
                    "end_line": {
                        "type": "integer",
                        "description": "ç»“æŸè¡Œå· (1-based, inclusive)ï¼Œä¸æŒ‡å®šåˆ™ä» start_line å¼€å§‹è¯»å–æœ€å¤š 200 è¡Œ",
                    },
                },
                "required": ["path"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "search_text",
            "description": (
                "åœ¨é¡¹ç›®æ–‡ä»¶ä¸­æœç´¢æ–‡æœ¬æˆ–æ­£åˆ™è¡¨è¾¾å¼ï¼Œè¿”å›åŒ¹é…çš„æ–‡ä»¶è·¯å¾„ã€è¡Œå·å’Œä¸Šä¸‹æ–‡ã€‚"
                "è¿™æ˜¯æœ€é«˜æ•ˆçš„ä»£ç å®šä½å·¥å…·â€”â€”å…ˆæœç´¢ç¡®å®šä½ç½®ï¼Œå†ç”¨ read_file çš„ start_line ç²¾ç¡®è¯»å–ã€‚"
                "åŠ¡å¿…æŒ‡å®š include_pattern ç¼©å°æœç´¢èŒƒå›´ï¼ˆå¦‚ '*.py', '*.vue'ï¼‰ï¼Œ"
                "å¦åˆ™ç»“æœå¯èƒ½è¿‡å¤šã€‚è¿”å›çš„è¡Œå·å¯ç›´æ¥ç”¨äº read_file çš„ start_line å‚æ•°ã€‚"
            ),
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "æœç´¢çš„æ–‡æœ¬æˆ–æ­£åˆ™è¡¨è¾¾å¼",
                    },
                    "is_regex": {
                        "type": "boolean",
                        "description": "æ˜¯å¦ä¸ºæ­£åˆ™è¡¨è¾¾å¼ï¼Œé»˜è®¤ false (ç²¾ç¡®æ–‡æœ¬æœç´¢)",
                        "default": False,
                    },
                    "include_pattern": {
                        "type": "string",
                        "description": (
                            "æ–‡ä»¶å glob è¿‡æ»¤ï¼Œå¦‚ '*.py'ã€'*.vue'ã€'*.ts'ã€‚"
                            "å¼ºçƒˆå»ºè®®å§‹ç»ˆæŒ‡å®šï¼Œé¿å…æœç´¢å…¨éƒ¨æ–‡ä»¶ç±»å‹"
                        ),
                    },
                },
                "required": ["query"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "list_directory",
            "description": (
                "åˆ—å‡ºç›®å½•ä¸‹çš„æ–‡ä»¶å’Œå­ç›®å½•ã€‚ç”¨äºäº†è§£é¡¹ç›®å±€éƒ¨ç»“æ„ã€‚"
                "å»ºè®®å…ˆç”¨ get_file_tree è·å–æ•´ä½“æ¦‚è§ˆï¼Œå†ç”¨æ­¤å·¥å…·æŸ¥çœ‹ç‰¹å®šç›®å½•çš„è¯¦ç»†å†…å®¹ã€‚"
            ),
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {
                        "type": "string",
                        "description": "ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•çš„ç›®å½•è·¯å¾„ï¼Œä¾‹å¦‚ 'backend/app/api'ã€‚ç©ºå­—ç¬¦ä¸²è¡¨ç¤ºé¡¹ç›®æ ¹ç›®å½•ã€‚",
                        "default": "",
                    },
                },
                "required": [],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "get_file_tree",
            "description": (
                "è·å–é¡¹ç›®å®Œæ•´æ–‡ä»¶æ ‘ï¼ˆå¸¦ç¼©è¿›çš„æ ‘çŠ¶ç»“æ„ï¼‰ã€‚"
                "é€‚åˆåœ¨å¯¹è¯å¼€å§‹æ—¶è°ƒç”¨ä¸€æ¬¡ï¼Œå¿«é€Ÿäº†è§£é¡¹ç›®æ•´ä½“ç»“æ„ï¼Œ"
                "å†æ ¹æ®ç»“æ„å†³å®šè¯»å–å“ªäº›æ–‡ä»¶ã€‚è‡ªåŠ¨è¿‡æ»¤ node_modulesã€.git ç­‰æ— å…³ç›®å½•ã€‚"
            ),
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {
                        "type": "string",
                        "description": "å­ç›®å½•è·¯å¾„ (ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•)ï¼Œç©ºå­—ç¬¦ä¸²è¡¨ç¤ºæ•´ä¸ªé¡¹ç›®",
                        "default": "",
                    },
                    "max_depth": {
                        "type": "integer",
                        "description": "ç›®å½•æ ‘æœ€å¤§æ·±åº¦ï¼Œé»˜è®¤ 3",
                        "default": 3,
                    },
                },
                "required": [],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "ask_user",
            "description": (
                "å‘ç”¨æˆ·æå‡ºéœ€è¦æ¾„æ¸…çš„é—®é¢˜ã€‚å½“æè¿°æ¨¡ç³Šã€æœ‰å¤šç§ç†è§£æ–¹å¼ã€"
                "æˆ–ç¼ºå°‘å…³é”®ä¿¡æ¯æ—¶ï¼Œä¸»åŠ¨è°ƒç”¨æ­¤å·¥å…·æé—®ã€‚å¯ä»¥ä¸€æ¬¡æå‡ºå¤šä¸ªé—®é¢˜ã€‚\n\n"
                "## ä½¿ç”¨è§„èŒƒ\n"
                "- æ¯ä¸ªé—®é¢˜é€šè¿‡ type æŒ‡å®š 'single'(å•é€‰) æˆ– 'multi'(å¤šé€‰)\n"
                "- options æ•°ç»„ä¸­çš„é€‰é¡¹æŒ‰æ¨èç¨‹åº¦ä»é«˜åˆ°ä½æ’åˆ—\n"
                "- ä¸ºæœ€æ¨èçš„ 1-2 ä¸ªé€‰é¡¹è®¾ç½® recommended: true\n"
                "- å•é€‰é¢˜æœ€åä¸€ä¸ªé€‰é¡¹é€šå¸¸æ˜¯'å…¶ä»–ï¼ˆè¯·è¯´æ˜ï¼‰'ä¹‹ç±»çš„è‡ªå®šä¹‰é€‰é¡¹ï¼Œé™¤éæ˜¯ä¸¥æ ¼å‡ é€‰ä¸€\n"
                "- ç”¨ context å­—æ®µç®€è¦è¯´æ˜ä¸ºä»€ä¹ˆéœ€è¦æ˜ç¡®è¿™ä¸ªé—®é¢˜\n"
                "- è°ƒç”¨æ­¤å·¥å…·åä½ å¿…é¡»åœæ­¢ï¼Œç­‰å¾…ç”¨æˆ·å›ç­”åå†ç»§ç»­\n"
            ),
            "parameters": {
                "type": "object",
                "properties": {
                    "questions": {
                        "type": "array",
                        "description": "é—®é¢˜åˆ—è¡¨",
                        "items": {
                            "type": "object",
                            "properties": {
                                "question": {
                                    "type": "string",
                                    "description": "é—®é¢˜æ–‡æœ¬",
                                },
                                "type": {
                                    "type": "string",
                                    "enum": ["single", "multi"],
                                    "description": "å•é€‰ single æˆ–å¤šé€‰ multiï¼Œé»˜è®¤ single",
                                },
                                "options": {
                                    "type": "array",
                                    "description": "é€‰é¡¹åˆ—è¡¨ï¼ŒæŒ‰æ¨èç¨‹åº¦ä»é«˜åˆ°ä½æ’åˆ—",
                                    "items": {
                                        "type": "object",
                                        "properties": {
                                            "label": {
                                                "type": "string",
                                                "description": "é€‰é¡¹æ–‡æœ¬",
                                            },
                                            "description": {
                                                "type": "string",
                                                "description": "é€‰é¡¹çš„è¡¥å……è¯´æ˜ï¼ˆå¯é€‰ï¼‰",
                                            },
                                            "recommended": {
                                                "type": "boolean",
                                                "description": "æ˜¯å¦ä¸ºæ¨èé€‰é¡¹",
                                            },
                                        },
                                        "required": ["label"],
                                    },
                                },
                                "context": {
                                    "type": "string",
                                    "description": "ä¸ºä»€ä¹ˆéœ€è¦æ˜ç¡®è¿™ä¸ªé—®é¢˜ï¼ˆç®€è¦è¯´æ˜å¯¹éœ€æ±‚çš„å½±å“ï¼‰",
                                },
                            },
                            "required": ["question"],
                        },
                    },
                },
                "required": ["questions"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "run_command",
            "description": (
                "åœ¨é¡¹ç›®å·¥ä½œç›®å½•ä¸­æ‰§è¡Œ shell å‘½ä»¤ã€‚âš ï¸ å½“ç”¨æˆ·è¦æ±‚ä½ æ‰§è¡Œå‘½ä»¤æ—¶ï¼Œ"
                "ä½ å¿…é¡»è°ƒç”¨æ­¤å·¥å…·ï¼Œç¦æ­¢åœ¨æ–‡æœ¬ä¸­ç¼–é€ æ‰§è¡Œç»“æœã€‚\n\n"
                "æ”¯æŒå¸¸ç”¨çš„åªè¯»å‘½ä»¤å¦‚ "
                "git (log, diff, show, status, blame), ls, cat, head, tail, find, "
                "grep, wc, diff, python3 -c ç­‰ã€‚éåªè¯»å‘½ä»¤éœ€è¦é¢å¤–æˆæƒã€‚\n\n"
                "å¸¸ç”¨åœºæ™¯ï¼š\n"
                "- `git log --oneline -20` æŸ¥çœ‹è¿‘ 20 æ¡æäº¤\n"
                "- `git diff origin/main...HEAD -- path/to/file` æŸ¥çœ‹å•æ–‡ä»¶å˜æ›´\n"
                "- `git diff --stat origin/main...HEAD` æŸ¥çœ‹å˜æ›´ç»Ÿè®¡\n"
                "- `git blame path/to/file` æŸ¥çœ‹æ–‡ä»¶é€è¡Œè´Ÿè´£äºº\n"
                "- `find . -name '*.py' -newer some_file` æŸ¥æ‰¾æ–°ä¿®æ”¹çš„æ–‡ä»¶\n"
                "- `python3 -c \"import json; ...\"` æ‰§è¡Œç®€å•è„šæœ¬\n"
                "- `docker ps` æŸ¥çœ‹è¿è¡Œä¸­çš„å®¹å™¨\n"
                "- `rm file` åˆ é™¤æ–‡ä»¶ (éœ€æˆæƒ)\n"
                "- `touch file` åˆ›å»ºæ–‡ä»¶ (éœ€æˆæƒ)\n"
            ),
            "parameters": {
                "type": "object",
                "properties": {
                    "command": {
                        "type": "string",
                        "description": "è¦æ‰§è¡Œçš„ shell å‘½ä»¤ (å•è¡Œ)",
                    },
                },
                "required": ["command"],
            },
        },
    },
]

# ==================== DB å·¥å…·ç¼“å­˜ ====================

# ä» DB åŠ è½½çš„å·¥å…·å®šä¹‰ç¼“å­˜ (å¯åŠ¨æ—¶ + API æ›´æ–°æ—¶åˆ·æ–°)
_db_tool_cache: Optional[List[Dict[str, Any]]] = None
_db_perm_map_cache: Optional[Dict[str, Set[str]]] = None


async def load_tools_from_db():
    """ä» DB åŠ è½½å·¥å…·å®šä¹‰åˆ°å†…å­˜ç¼“å­˜ (å¯åŠ¨æ—¶è°ƒç”¨)"""
    global _db_tool_cache, _db_perm_map_cache
    try:
        from studio.backend.core.database import async_session_maker
        from studio.backend.models import ToolDefinition
        from sqlalchemy import select

        async with async_session_maker() as db:
            result = await db.execute(
                select(ToolDefinition)
                .where(ToolDefinition.is_enabled.is_(True))
                .order_by(ToolDefinition.sort_order, ToolDefinition.id)
            )
            tools = result.scalars().all()

        _db_tool_cache = []
        _db_perm_map_cache = {}
        for t in tools:
            func_def = t.function_def or {}
            tool_name = func_def.get("name", t.name)
            _db_tool_cache.append({
                "type": "function",
                "function": func_def,
            })
            _db_perm_map_cache[tool_name] = {t.permission_key}

        logger.info(f"âœ… ä» DB åŠ è½½äº† {len(_db_tool_cache)} ä¸ªå·¥å…·å®šä¹‰åˆ°ç¼“å­˜")
    except Exception as e:
        logger.warning(f"âš ï¸ ä» DB åŠ è½½å·¥å…·å®šä¹‰å¤±è´¥, ä½¿ç”¨ç¡¬ç¼–ç  fallback: {e}")
        _db_tool_cache = None
        _db_perm_map_cache = None


def get_tool_definitions(permissions: Optional[Set[str]] = None) -> list:
    """
    è·å–å½“å‰å¯ç”¨çš„å·¥å…·å®šä¹‰åˆ—è¡¨ (æ ¹æ®æƒé™è¿‡æ»¤)

    ä¼˜å…ˆä½¿ç”¨ DB ç¼“å­˜, å›é€€åˆ°ç¡¬ç¼–ç  TOOL_DEFINITIONS

    Args:
        permissions: å…è®¸çš„æƒé™é›†åˆï¼ŒNone è¡¨ç¤ºä½¿ç”¨é»˜è®¤æƒé™ (å…¨éƒ¨å¼€å¯)

    Returns:
        OpenAI tools format åˆ—è¡¨
    """
    perms = permissions or DEFAULT_PERMISSIONS

    # ä½¿ç”¨ DB ç¼“å­˜
    tool_defs = _db_tool_cache if _db_tool_cache is not None else TOOL_DEFINITIONS
    perm_map = _db_perm_map_cache if _db_perm_map_cache is not None else _TOOL_PERMISSION_MAP

    tools = []
    for tool_def in tool_defs:
        name = tool_def["function"]["name"]
        required_perm = perm_map.get(name)
        if required_perm and required_perm.issubset(perms):
            tools.append(tool_def)

    return tools


# å·¥å…·å â†’ æ‰€éœ€æƒé™æ˜ å°„
_TOOL_PERMISSION_MAP: Dict[str, Set[str]] = {
    "ask_user": {"ask_user"},
    "read_file": {"read_source"},
    "search_text": {"search"},
    "list_directory": {"tree"},
    "get_file_tree": {"tree"},
    "run_command": {"execute_readonly_command"},
}


# ==================== è·¯å¾„å®‰å…¨æ£€æŸ¥ ====================

def _validate_path(workspace: str, rel_path: str) -> Tuple[bool, str, str]:
    """
    éªŒè¯è·¯å¾„å®‰å…¨æ€§

    Returns:
        (is_safe, absolute_path, error_message)
    """
    # è§„èŒƒåŒ–è·¯å¾„
    rel_path = rel_path.strip().lstrip("/")

    # é˜»æ­¢ç©ºè·¯å¾„ç”¨äºæ–‡ä»¶æ“ä½œ
    abs_path = os.path.realpath(os.path.join(workspace, rel_path))

    # æ²™ç®±æ£€æŸ¥: å¿…é¡»åœ¨ workspace å†…
    workspace_real = os.path.realpath(workspace)
    if not abs_path.startswith(workspace_real + os.sep) and abs_path != workspace_real:
        return False, abs_path, f"âš ï¸ è·¯å¾„è¶Šç•Œ: '{rel_path}' ä¸åœ¨é¡¹ç›®ç›®å½•å†…"

    return True, abs_path, ""


def _is_sensitive_file(rel_path: str) -> bool:
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åœ¨æ•æ„Ÿé»‘åå•ä¸­"""
    basename = os.path.basename(rel_path)
    _, ext = os.path.splitext(basename)

    # å…è®¸åˆ—è¡¨ä¼˜å…ˆ
    if basename in _CONFIG_ALLOWLIST:
        return False

    # ç²¾ç¡®æ–‡ä»¶ååŒ¹é…
    if basename in _SENSITIVE_PATTERNS:
        return True

    # æ‰©å±•ååŒ¹é…
    if ext.lower() in _SENSITIVE_EXTENSIONS:
        return True

    # è·¯å¾„ä¸­åŒ…å«æ•æ„Ÿç›®å½•
    path_parts = rel_path.replace("\\", "/").split("/")
    for part in path_parts:
        if part in _SENSITIVE_PATTERNS:
            return True

    return False


# ==================== å·¥å…·æ‰§è¡Œå™¨ ====================

# ç±»å‹: å‘½ä»¤å®¡æ‰¹å›è°ƒ (command_str, tool_call_id) -> {"approved": bool, "scope": str}
CommandApprovalCallback = Optional[Any]  # asyncio coroutine

async def execute_tool(
    name: str,
    arguments: Dict[str, Any],
    workspace: str,
    permissions: Optional[Set[str]] = None,
    command_approval_fn: CommandApprovalCallback = None,
) -> str:
    """
    æ‰§è¡ŒæŒ‡å®šå·¥å…·å¹¶è¿”å›ç»“æœæ–‡æœ¬

    Args:
        name: å·¥å…·åç§°
        arguments: å·¥å…·å‚æ•°
        workspace: å·¥ä½œåŒºæ ¹è·¯å¾„
        permissions: å…è®¸çš„æƒé™é›†åˆ
        command_approval_fn: å¼‚æ­¥å›è°ƒ, ç”¨äºè¯·æ±‚ç”¨æˆ·æ‰¹å‡†å†™å‘½ä»¤
                            ç­¾å: async (command: str, tool_call_id: str) -> {"approved": bool, "scope": str}

    Returns:
        å·¥å…·æ‰§è¡Œç»“æœ (çº¯æ–‡æœ¬)
    """
    perms = permissions or DEFAULT_PERMISSIONS

    # æƒé™æ£€æŸ¥
    required_perm = _TOOL_PERMISSION_MAP.get(name)
    if required_perm and not required_perm.issubset(perms):
        return f"âš ï¸ å·¥å…· '{name}' å·²è¢«é¡¹ç›®ç®¡ç†å‘˜ç¦ç”¨"

    # run_command ç‰¹æ®Šå¤„ç†: éåªè¯»å‘½ä»¤éœ€è¦ execute_command æƒé™ + ç”¨æˆ·å®¡æ‰¹
    if name == "run_command":
        command = arguments.get("command", "")
        if not _is_readonly_command(command):
            if "execute_command" not in perms:
                # å†™å‘½ä»¤æƒé™æœªå¼€å¯ â€” å®Œå…¨é˜»æ­¢
                return (
                    f"âš ï¸ æ­¤å‘½ä»¤ä¸åœ¨åªè¯»ç™½åå•ä¸­ï¼Œä¸”é¡¹ç›®æœªå¼€å¯ã€Œæ‰§è¡Œå†™å…¥å‘½ä»¤ã€æƒé™ã€‚\n"
                    f"å‘½ä»¤: {command}\n\n"
                    f"åªè¯»å‘½ä»¤ç¤ºä¾‹: git log, git diff, ls, cat, grep, find, python3 -c ç­‰\n"
                    f"å¦‚éœ€æ‰§è¡Œæ­¤å‘½ä»¤ï¼Œè¯·è®©ç”¨æˆ·åœ¨å·¥å…·é¢æ¿ä¸­å¼€å¯ã€Œâš ï¸ æ‰§è¡Œå†™å…¥å‘½ä»¤ã€æƒé™ã€‚"
                )
            # å†™å‘½ä»¤æƒé™å·²å¼€å¯ â€” ä»éœ€é€šè¿‡å®¡æ‰¹æµç¨‹
            if command_approval_fn:
                # è¯·æ±‚ç”¨æˆ·å®æ—¶å®¡æ‰¹ (å›è°ƒå†…éƒ¨å¤„ç† session/project çº§ç¼“å­˜)
                approval = await command_approval_fn(command, "")
                if approval.get("approved"):
                    try:
                        result = await asyncio.wait_for(
                            _tool_run_command_unrestricted(arguments, workspace),
                            timeout=COMMAND_TIMEOUT_SECONDS * 2,
                        )
                        scope_label = {"once": "æœ¬æ¬¡", "session": "æœ¬ä¼šè¯", "project": "æœ¬é¡¹ç›®", "permanent": "æ°¸ä¹…", "rule": "è§„åˆ™åŒ¹é…"}.get(approval.get("scope", ""), "")
                        if scope_label:
                            return f"âœ… ç”¨æˆ·å·²æˆæƒæ‰§è¡Œ ({scope_label})\n\n{result}"
                        return result
                    except asyncio.TimeoutError:
                        return f"âš ï¸ å‘½ä»¤æ‰§è¡Œè¶…æ—¶"
                    except Exception as e:
                        logger.exception(f"å‘½ä»¤æ‰§è¡Œå¤±è´¥")
                        return f"âš ï¸ å‘½ä»¤æ‰§è¡Œå¤±è´¥: {str(e)}"
                else:
                    reason = approval.get("reason", "ç”¨æˆ·æ‹’ç»")
                    return (
                        f"âš ï¸ ç”¨æˆ·æ‹’ç»æ‰§è¡Œæ­¤å‘½ä»¤ã€‚\n"
                        f"å‘½ä»¤: {command}\n"
                        f"åŸå› : {reason}\n\n"
                        f"è¯·æ”¹ç”¨åªè¯»å‘½ä»¤è·å–ä¿¡æ¯ï¼Œæˆ–å‘ç”¨æˆ·è§£é‡Šä¸ºä»€ä¹ˆéœ€è¦æ‰§è¡Œæ­¤å‘½ä»¤åå†æ¬¡å°è¯•ã€‚"
                    )
            else:
                # æ— å®¡æ‰¹å›è°ƒ (éä»»åŠ¡ä¸Šä¸‹æ–‡, å¦‚ç›´æ¥ API è°ƒç”¨) â€” ç›´æ¥æ‰§è¡Œ
                try:
                    result = await asyncio.wait_for(
                        _tool_run_command_unrestricted(arguments, workspace),
                        timeout=COMMAND_TIMEOUT_SECONDS * 2,
                    )
                    return result
                except asyncio.TimeoutError:
                    return f"âš ï¸ å‘½ä»¤æ‰§è¡Œè¶…æ—¶"
                except Exception as e:
                    logger.exception(f"å‘½ä»¤æ‰§è¡Œå¤±è´¥")
                    return f"âš ï¸ å‘½ä»¤æ‰§è¡Œå¤±è´¥: {str(e)}"

    # æ‰§è¡Œå·¥å…· (å¸¦è¶…æ—¶)
    executor = _TOOL_EXECUTORS.get(name)
    if not executor:
        return f"âš ï¸ æœªçŸ¥å·¥å…·: '{name}'"

    timeout = COMMAND_TIMEOUT_SECONDS if name == "run_command" else TOOL_TIMEOUT_SECONDS
    try:
        result = await asyncio.wait_for(
            executor(arguments, workspace),
            timeout=timeout,
        )
        return result
    except asyncio.TimeoutError:
        return f"âš ï¸ å·¥å…· '{name}' æ‰§è¡Œè¶…æ—¶ ({timeout}s)"
    except Exception as e:
        logger.exception(f"å·¥å…· {name} æ‰§è¡Œå¤±è´¥")
        return f"âš ï¸ å·¥å…·æ‰§è¡Œå¤±è´¥: {str(e)}"


# ==================== å…·ä½“å·¥å…·å®ç° ====================

async def _tool_read_file(args: Dict[str, Any], workspace: str) -> str:
    """è¯»å–æ–‡ä»¶å†…å®¹"""
    path = args.get("path", "")
    start_line = args.get("start_line", 1)
    end_line = args.get("end_line")

    if not path:
        return "âš ï¸ è¯·æŒ‡å®šæ–‡ä»¶è·¯å¾„"

    # è·¯å¾„å®‰å…¨æ£€æŸ¥
    is_safe, abs_path, error = _validate_path(workspace, path)
    if not is_safe:
        return error

    # æ•æ„Ÿæ–‡ä»¶æ£€æŸ¥
    if _is_sensitive_file(path):
        return f"âš ï¸ æ— æ³•è¯»å–æ•æ„Ÿæ–‡ä»¶: '{path}'"

    if not os.path.exists(abs_path):
        return f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: '{path}'"

    if not os.path.isfile(abs_path):
        return f"âš ï¸ '{path}' ä¸æ˜¯æ–‡ä»¶ (å¯èƒ½æ˜¯ç›®å½•ï¼Œè¯·ä½¿ç”¨ list_directory)"

    # æ£€æŸ¥æ–‡ä»¶å¤§å° (è·³è¿‡è¿‡å¤§çš„äºŒè¿›åˆ¶æ–‡ä»¶)
    file_size = os.path.getsize(abs_path)
    if file_size > 1024 * 1024:  # 1MB
        return f"âš ï¸ æ–‡ä»¶è¿‡å¤§ ({file_size / 1024:.0f}KB)ï¼Œè¯·æŒ‡å®šè¡ŒèŒƒå›´è¯»å–"

    try:
        with open(abs_path, "r", encoding="utf-8", errors="replace") as f:
            lines = f.readlines()
    except UnicodeDecodeError:
        return f"âš ï¸ '{path}' æ˜¯äºŒè¿›åˆ¶æ–‡ä»¶ï¼Œæ— æ³•è¯»å–"

    total_lines = len(lines)

    # å¤„ç†è¡ŒèŒƒå›´
    start = max(1, start_line or 1)
    end = min(total_lines, end_line or (start + MAX_READ_LINES - 1))

    # æœ€å¤šè¯»å– MAX_READ_LINES è¡Œ
    if end - start + 1 > MAX_READ_LINES:
        end = start + MAX_READ_LINES - 1

    selected = lines[start - 1:end]
    content = "".join(selected)

    # æ„å»ºç»“æœå¤´ä¿¡æ¯
    header = f"ğŸ“„ {path} (è¡Œ {start}-{end}, å…± {total_lines} è¡Œ)"
    if end < total_lines:
        header += f" [æˆªæ–­: ä½¿ç”¨ start_line/end_line æŸ¥çœ‹æ›´å¤š]"

    return f"{header}\n```\n{content}```"


async def _tool_search_text(args: Dict[str, Any], workspace: str) -> str:
    """å…¨æ–‡æœç´¢"""
    query = args.get("query", "")
    is_regex = args.get("is_regex", False)
    include_pattern = args.get("include_pattern", "")

    if not query:
        return "âš ï¸ è¯·æŒ‡å®šæœç´¢å†…å®¹"

    # æ„å»º grep å‘½ä»¤
    cmd = ["grep", "-rn", "--color=never"]

    if is_regex:
        cmd.append("-E")
    else:
        cmd.append("-F")

    # ä¸Šä¸‹æ–‡è¡Œ
    cmd.extend(["-B", str(SEARCH_CONTEXT_LINES), "-A", str(SEARCH_CONTEXT_LINES)])

    # æœ€å¤§ç»“æœæ•°
    cmd.extend(["-m", str(MAX_SEARCH_RESULTS)])

    # æ’é™¤ç›®å½•
    for skip_dir in TREE_SKIP_DIRS:
        cmd.extend(["--exclude-dir", skip_dir])

    # æ’é™¤æ•æ„Ÿæ–‡ä»¶
    for ext in _SENSITIVE_EXTENSIONS:
        cmd.extend(["--exclude", f"*{ext}"])
    cmd.extend(["--exclude", ".env*"])

    # åŒ…å«æ¨¡å¼ (ä¿®æ­£: grep --include ä¸æ”¯æŒ ** æˆ–è·¯å¾„, åªæ”¯æŒæ–‡ä»¶å glob)
    if include_pattern:
        # å»æ‰è·¯å¾„å‰ç¼€ (å¦‚ **/*.py â†’ *.py, src/**/*.ts â†’ *.ts)
        clean_pattern = include_pattern
        if '/' in clean_pattern:
            clean_pattern = clean_pattern.rsplit('/', 1)[-1]
        if not clean_pattern or clean_pattern == '**':
            clean_pattern = '*'
        cmd.extend(["--include", clean_pattern])

    cmd.append(query)
    cmd.append(".")

    try:
        proc = await asyncio.create_subprocess_exec(
            *cmd,
            cwd=workspace,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
        )
        stdout, stderr = await asyncio.wait_for(proc.communicate(), timeout=TOOL_TIMEOUT_SECONDS)
        output = stdout.decode("utf-8", errors="replace").strip()

        if not output:
            return f"ğŸ” æœªæ‰¾åˆ°åŒ¹é…: '{query}'"

        # æ¸…ç†è·¯å¾„ (å»æ‰ ./ å‰ç¼€)
        output = output.replace("\n./", "\n").lstrip("./")

        # é™åˆ¶è¾“å‡ºé•¿åº¦ (è¡Œæ•° + å­—ç¬¦æ•°åŒé‡é™åˆ¶)
        MAX_OUTPUT_LINES = 120
        MAX_OUTPUT_CHARS = 6000
        lines = output.split("\n")
        if len(lines) > MAX_OUTPUT_LINES:
            output = "\n".join(lines[:MAX_OUTPUT_LINES])
            output += f"\n\n... (ç»“æœè¿‡å¤šï¼Œå·²æˆªæ–­è‡³ {MAX_OUTPUT_LINES} è¡Œã€‚è¯·ä½¿ç”¨ include_pattern ç¼©å°èŒƒå›´)"
        if len(output) > MAX_OUTPUT_CHARS:
            output = output[:MAX_OUTPUT_CHARS]
            output += f"\n\n... (è¾“å‡ºè¿‡é•¿ï¼Œå·²æˆªæ–­è‡³ {MAX_OUTPUT_CHARS} å­—ç¬¦ã€‚è¯·ç¼©å°æœç´¢èŒƒå›´æˆ–æŒ‡å®š include_pattern)"

        pattern_desc = f"æ­£åˆ™ '{query}'" if is_regex else f"'{query}'"
        scope = f" (èŒƒå›´: {include_pattern})" if include_pattern else ""
        return f"ğŸ” æœç´¢ {pattern_desc}{scope}:\n\n{output}"

    except FileNotFoundError:
        # grep ä¸å¯ç”¨ï¼Œé€€å›åˆ° Python å®ç°
        return await _python_search(query, is_regex, include_pattern, workspace)


async def _python_search(
    query: str, is_regex: bool, include_pattern: str, workspace: str,
) -> str:
    """Python å¤‡ç”¨æœç´¢å®ç° (grep ä¸å¯ç”¨æ—¶)"""
    import fnmatch

    if is_regex:
        try:
            pattern = re.compile(query, re.IGNORECASE)
        except re.error as e:
            return f"âš ï¸ æ— æ•ˆçš„æ­£åˆ™è¡¨è¾¾å¼: {e}"
    else:
        pattern = None

    results: List[str] = []
    count = 0

    for root, dirs, files in os.walk(workspace):
        # è·³è¿‡æ’é™¤ç›®å½•
        dirs[:] = [d for d in dirs if d not in TREE_SKIP_DIRS]

        for fname in files:
            if count >= MAX_SEARCH_RESULTS:
                break

            # æ•æ„Ÿæ–‡ä»¶æ£€æŸ¥
            rel_path = os.path.relpath(os.path.join(root, fname), workspace)
            if _is_sensitive_file(rel_path):
                continue

            # include_pattern è¿‡æ»¤
            if include_pattern and not fnmatch.fnmatch(fname, include_pattern):
                continue

            try:
                with open(os.path.join(root, fname), "r", encoding="utf-8", errors="replace") as f:
                    file_lines = f.readlines()
            except Exception:
                continue

            for i, line in enumerate(file_lines):
                if count >= MAX_SEARCH_RESULTS:
                    break

                matched = False
                if pattern:
                    matched = bool(pattern.search(line))
                else:
                    matched = query.lower() in line.lower()

                if matched:
                    count += 1
                    line_num = i + 1
                    # ä¸Šä¸‹æ–‡
                    ctx_start = max(0, i - SEARCH_CONTEXT_LINES)
                    ctx_end = min(len(file_lines), i + SEARCH_CONTEXT_LINES + 1)
                    ctx = ""
                    for j in range(ctx_start, ctx_end):
                        prefix = ">" if j == i else " "
                        ctx += f"{prefix} {j+1}: {file_lines[j]}"
                    results.append(f"{rel_path}:{line_num}\n{ctx}")

    if not results:
        return f"ğŸ” æœªæ‰¾åˆ°åŒ¹é…: '{query}'"

    output = "\n---\n".join(results)
    truncated = f"\n\n... (å·²è¾¾åˆ° {MAX_SEARCH_RESULTS} æ¡ä¸Šé™)" if count >= MAX_SEARCH_RESULTS else ""
    return f"ğŸ” æœç´¢ '{query}' æ‰¾åˆ° {count} ä¸ªåŒ¹é…:\n\n{output}{truncated}"


async def _tool_list_directory(args: Dict[str, Any], workspace: str) -> str:
    """åˆ—å‡ºç›®å½•å†…å®¹"""
    path = args.get("path", "")

    # è·¯å¾„å®‰å…¨æ£€æŸ¥
    is_safe, abs_path, error = _validate_path(workspace, path or ".")
    if not is_safe:
        return error

    if not os.path.exists(abs_path):
        return f"âš ï¸ ç›®å½•ä¸å­˜åœ¨: '{path}'"

    if not os.path.isdir(abs_path):
        return f"âš ï¸ '{path}' ä¸æ˜¯ç›®å½• (è¯·ä½¿ç”¨ read_file è¯»å–æ–‡ä»¶)"

    try:
        entries = sorted(os.listdir(abs_path))
    except PermissionError:
        return f"âš ï¸ æ— æƒè®¿é—®: '{path}'"

    # è¿‡æ»¤éšè—å’Œå¿½ç•¥çš„ç›®å½•
    entries = [e for e in entries if e not in TREE_SKIP_DIRS and not e.startswith("__pycache__")]

    dirs = []
    files = []
    for entry in entries:
        full = os.path.join(abs_path, entry)
        if os.path.isdir(full):
            # è®¡ç®—å­é¡¹æ•°é‡
            try:
                sub_count = len(os.listdir(full))
            except Exception:
                sub_count = 0
            dirs.append(f"ğŸ“ {entry}/ ({sub_count} items)")
        else:
            size = os.path.getsize(full)
            size_str = f"{size}B" if size < 1024 else f"{size / 1024:.1f}KB" if size < 1048576 else f"{size / 1048576:.1f}MB"
            files.append(f"ğŸ“„ {entry} ({size_str})")

    display_path = path or "."
    result = f"ğŸ“‚ {display_path}/\n"
    result += "\n".join(dirs + files)

    if not dirs and not files:
        result += "(ç©ºç›®å½•)"

    return result


async def _tool_get_file_tree(args: Dict[str, Any], workspace: str) -> str:
    """è·å–ç›®å½•æ ‘"""
    path = args.get("path", "")
    max_depth = min(args.get("max_depth", 3), MAX_TREE_DEPTH)

    # è·¯å¾„å®‰å…¨æ£€æŸ¥
    target = os.path.join(workspace, path) if path else workspace
    is_safe, abs_path, error = _validate_path(workspace, path or ".")
    if not is_safe:
        return error

    if not os.path.exists(abs_path):
        return f"âš ï¸ è·¯å¾„ä¸å­˜åœ¨: '{path}'"

    if not os.path.isdir(abs_path):
        return f"âš ï¸ '{path}' ä¸æ˜¯ç›®å½•"

    tree = _build_tree(abs_path, max_depth)
    display_path = path or "."
    return f"ğŸŒ³ {display_path}/ ç›®å½•æ ‘ (æ·±åº¦: {max_depth}):\n\n{tree}"


def _build_tree(path: str, max_depth: int, prefix: str = "", depth: int = 0) -> str:
    """é€’å½’æ„å»ºç›®å½•æ ‘"""
    if depth >= max_depth:
        return ""

    try:
        entries = sorted(os.listdir(path))
    except PermissionError:
        return f"{prefix}(æ— æƒé™è®¿é—®)\n"

    # è¿‡æ»¤
    entries = [e for e in entries if e not in TREE_SKIP_DIRS and not e.startswith(".")]

    lines = []
    for i, entry in enumerate(entries):
        is_last = i == len(entries) - 1
        connector = "â””â”€â”€ " if is_last else "â”œâ”€â”€ "
        full_path = os.path.join(path, entry)

        if os.path.isdir(full_path):
            lines.append(f"{prefix}{connector}{entry}/")
            extension = "    " if is_last else "â”‚   "
            subtree = _build_tree(full_path, max_depth, prefix + extension, depth + 1)
            if subtree:
                lines.append(subtree)
        else:
            lines.append(f"{prefix}{connector}{entry}")

    return "\n".join(lines)


async def _tool_ask_user(args: Dict[str, Any], workspace: str) -> str:
    """å‘ç”¨æˆ·æå‡ºéœ€æ±‚æ¾„æ¸…é—®é¢˜ (ç»“æœç›´æ¥é€ä¼ ç»™å‰ç«¯æ¸²æŸ“)"""
    questions = args.get("questions", [])
    if not questions:
        return "âš ï¸ è¯·è‡³å°‘æå‡ºä¸€ä¸ªé—®é¢˜"
    count = len(questions)
    return f"âœ… å·²å‘ç”¨æˆ·å±•ç¤º {count} ä¸ªé—®é¢˜ï¼Œè¯·ç­‰å¾…ç”¨æˆ·å›ç­”åå†ç»§ç»­è®¨è®ºã€‚ä¸è¦è‡ªè¡Œå‡è®¾ç­”æ¡ˆã€‚"


# ==================== å‘½ä»¤æ‰§è¡Œå·¥å…· ====================

# åªè¯»å‘½ä»¤ç™½åå•: {å‘½ä»¤: å…è®¸çš„å­å‘½ä»¤é›†åˆ (None=å…¨éƒ¨å…è®¸)}
_READONLY_COMMANDS = {
    "git": {"log", "diff", "show", "status", "branch", "tag", "describe",
            "rev-parse", "ls-files", "blame", "shortlog", "remote", "stash"},
    "ls": None, "cat": None, "head": None, "tail": None,
    "find": None, "grep": None, "wc": None, "file": None,
    "diff": None, "pwd": None, "echo": None, "which": None,
    "du": None, "stat": None, "realpath": None, "dirname": None,
    "basename": None, "env": None, "uname": None, "whoami": None,
    "date": None, "tree": None, "less": None, "more": None,
    "sort": None, "uniq": None, "awk": None, "sed": None,
    "cut": None, "tr": None, "xargs": None,
    "python3": {"-c", "--version", "-V"},
    "python": {"-c", "--version", "-V"},
    "node": {"-e", "--version", "-v"},
    "docker": {"ps", "images", "logs", "inspect", "stats", "top", "version", "info"},
    "docker-compose": {"ps", "logs", "config", "images"},
}

# Shell å†™æ“ä½œç¬¦ â€” å‡ºç°åœ¨å‘½ä»¤ä¸­åˆ™è§†ä¸ºéåªè¯»
import re as _re
_WRITE_OPERATORS_PATTERN = _re.compile(
    r'(?:^|\s)'
    r'(?:'
    r'>|>>|'           # è¾“å‡ºé‡å®šå‘
    r'\|\s*tee\b|'     # tee å†™æ–‡ä»¶
    r'&&|;'            # é“¾å¼å‘½ä»¤ (å¯èƒ½åæ¥å†™å‘½ä»¤)
    r')'
)

COMMAND_TIMEOUT_SECONDS = 30


def _is_readonly_command(command_str: str) -> bool:
    """æ£€æŸ¥å‘½ä»¤æ˜¯å¦ä¸ºåªè¯»å‘½ä»¤

    æ£€æŸ¥å±‚çº§:
    1. å…¨å±€å†™æ“ä½œç¬¦æ£€æµ‹: >, >>, &&, ;, |tee ç­‰
    2. ç®¡é“é“¾: æ¯ä¸ªå­å‘½ä»¤éƒ½å¿…é¡»åœ¨ç™½åå•ä¸­
    3. ç™½åå•åŒ¹é…: å‘½ä»¤ + å­å‘½ä»¤æ£€æŸ¥
    """
    stripped = command_str.strip()
    if not stripped:
        return False

    # 1) æ£€æµ‹å†™æ“ä½œç¬¦ (>, >>, &&, ;, tee)
    # å…è®¸ç®¡é“ | ä½†ä¸å…è®¸ | tee
    if _re.search(r'>{1,2}', stripped):  # > or >>
        return False
    if '&&' in stripped or ';' in stripped:
        return False
    if _re.search(r'\|\s*tee\b', stripped):
        return False
    # æ£€æµ‹åå¼•å·/å­ shell æ‰§è¡Œ
    if '`' in stripped or '$(' in stripped:
        return False

    # 2) ç®¡é“é“¾: æ¯ä¸ªå­å‘½ä»¤éƒ½å¿…é¡»åœ¨ç™½åå•ä¸­
    pipe_segments = [s.strip() for s in stripped.split('|') if s.strip()]
    for seg in pipe_segments:
        parts = seg.split()
        if not parts:
            return False
        cmd = os.path.basename(parts[0])

        allowed_subs = _READONLY_COMMANDS.get(cmd)
        if allowed_subs is None and cmd in _READONLY_COMMANDS:
            continue  # è¯¥å‘½ä»¤ä»»ä½•å‚æ•°éƒ½å…è®¸
        if allowed_subs is not None:
            if len(parts) >= 2 and parts[1] in allowed_subs:
                continue
            elif len(parts) < 2:
                continue  # æ— å‚æ•°, è§†ä¸ºå®‰å…¨
            else:
                return False  # å­å‘½ä»¤ä¸åœ¨å…è®¸åˆ—è¡¨
        else:
            return False  # å‘½ä»¤ä¸åœ¨ç™½åå•

    return True


async def _tool_run_command(args: Dict[str, Any], workspace: str) -> str:
    """æ‰§è¡Œ shell å‘½ä»¤"""
    command = args.get("command", "").strip()
    if not command:
        return "âš ï¸ è¯·æŒ‡å®šè¦æ‰§è¡Œçš„å‘½ä»¤"

    # å®‰å…¨æ£€æŸ¥: é˜»æ­¢å±é™©æ¨¡å¼
    dangerous_patterns = ["rm -rf /", "mkfs", "dd if=", "> /dev/", ":(){ :|:& };:", "shutdown", "reboot"]
    for pattern in dangerous_patterns:
        if pattern in command:
            return f"âš ï¸ å‘½ä»¤åŒ…å«å±é™©æ¨¡å¼: '{pattern}'ï¼Œå·²é˜»æ­¢æ‰§è¡Œ"

    # ç®¡é“/é“¾å¼å‘½ä»¤: æ£€æŸ¥æ¯ä¸ªå­å‘½ä»¤
    # æ³¨: ç®€åŒ–æ£€æŸ¥ï¼Œåªæ£€æŸ¥ç¬¬ä¸€ä¸ªå‘½ä»¤çš„åªè¯»æ€§
    is_readonly = _is_readonly_command(command)

    if not is_readonly:
        # éåªè¯»å‘½ä»¤æç¤º
        return (
            f"âš ï¸ æ­¤å‘½ä»¤ä¸åœ¨åªè¯»ç™½åå•ä¸­ï¼Œéœ€è¦ 'æ‰§è¡Œä»»æ„å‘½ä»¤' æƒé™ã€‚\n"
            f"å‘½ä»¤: {command}\n\n"
            f"åªè¯»å‘½ä»¤ç¤ºä¾‹: git log, git diff, ls, cat, grep, find, python3 -c ç­‰\n"
            f"å¦‚éœ€æ‰§è¡Œæ­¤å‘½ä»¤ï¼Œè¯·è®©é¡¹ç›®ç®¡ç†å‘˜å¼€å¯ 'execute_command' æƒé™ã€‚"
        )

    try:
        proc = await asyncio.create_subprocess_shell(
            command,
            cwd=workspace,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
            env={**os.environ, "GIT_TERMINAL_PROMPT": "0"},
        )
        stdout, stderr = await asyncio.wait_for(
            proc.communicate(), timeout=COMMAND_TIMEOUT_SECONDS
        )
        out = stdout.decode("utf-8", errors="replace").strip()
        err = stderr.decode("utf-8", errors="replace").strip()

        # é™åˆ¶è¾“å‡ºé•¿åº¦
        MAX_CMD_OUTPUT = 8000
        if len(out) > MAX_CMD_OUTPUT:
            out = out[:MAX_CMD_OUTPUT] + f"\n\n... (è¾“å‡ºå·²æˆªæ–­è‡³ {MAX_CMD_OUTPUT} å­—ç¬¦)"

        result = f"$ {command}\n"
        if out:
            result += f"\n{out}"
        if err:
            result += f"\n(stderr) {err}"
        if proc.returncode != 0:
            result += f"\n(exit code: {proc.returncode})"

        return result

    except asyncio.TimeoutError:
        return f"âš ï¸ å‘½ä»¤æ‰§è¡Œè¶…æ—¶ ({COMMAND_TIMEOUT_SECONDS}s): {command}"
    except Exception as e:
        return f"âš ï¸ å‘½ä»¤æ‰§è¡Œå¤±è´¥: {str(e)}"


async def _tool_run_command_unrestricted(args: Dict[str, Any], workspace: str) -> str:
    """æ‰§è¡Œä»»æ„å‘½ä»¤ (éœ€è¦ execute_command æƒé™)"""
    command = args.get("command", "").strip()
    if not command:
        return "âš ï¸ è¯·æŒ‡å®šè¦æ‰§è¡Œçš„å‘½ä»¤"

    # ä»ç„¶é˜»æ­¢æç«¯å±é™©çš„å‘½ä»¤
    lethal = ["rm -rf /", "mkfs", "> /dev/", ":(){ :|:& };:", "shutdown", "reboot"]
    for pattern in lethal:
        if pattern in command:
            return f"âš ï¸ å‘½ä»¤åŒ…å«æç«¯å±é™©æ¨¡å¼: '{pattern}'ï¼Œå·²é˜»æ­¢æ‰§è¡Œ"

    try:
        proc = await asyncio.create_subprocess_shell(
            command,
            cwd=workspace,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
            env={**os.environ, "GIT_TERMINAL_PROMPT": "0"},
        )
        stdout, stderr = await asyncio.wait_for(
            proc.communicate(), timeout=COMMAND_TIMEOUT_SECONDS * 2  # å†™å‘½ä»¤ç»™æ›´å¤šæ—¶é—´
        )
        out = stdout.decode("utf-8", errors="replace").strip()
        err = stderr.decode("utf-8", errors="replace").strip()

        MAX_CMD_OUTPUT = 8000
        if len(out) > MAX_CMD_OUTPUT:
            out = out[:MAX_CMD_OUTPUT] + f"\n\n... (è¾“å‡ºå·²æˆªæ–­è‡³ {MAX_CMD_OUTPUT} å­—ç¬¦)"

        result = f"$ {command}\n"
        if out:
            result += f"\n{out}"
        if err:
            result += f"\n(stderr) {err}"
        if proc.returncode != 0:
            result += f"\n(exit code: {proc.returncode})"

        return result

    except asyncio.TimeoutError:
        return f"âš ï¸ å‘½ä»¤æ‰§è¡Œè¶…æ—¶ ({COMMAND_TIMEOUT_SECONDS * 2}s): {command}"
    except Exception as e:
        return f"âš ï¸ å‘½ä»¤æ‰§è¡Œå¤±è´¥: {str(e)}"


# å·¥å…·æ‰§è¡Œå™¨æ˜ å°„
_TOOL_EXECUTORS: Dict[str, Callable] = {
    "read_file": _tool_read_file,
    "search_text": _tool_search_text,
    "list_directory": _tool_list_directory,
    "get_file_tree": _tool_get_file_tree,
    "ask_user": _tool_ask_user,
    "run_command": _tool_run_command,
}
