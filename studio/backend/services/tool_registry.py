"""
è®¾è®¡é™¢ (Studio) - å·¥å…·æ³¨å†Œè¡¨ä¸æ‰§è¡Œå¼•æ“

ä¸º AI è®¨è®ºæä¾›ä»£ç æ„ŸçŸ¥èƒ½åŠ›:
  - read_file: è¯»å–é¡¹ç›®æ–‡ä»¶å†…å®¹
  - search_text: å…¨æ–‡æœç´¢ (æ”¯æŒæ­£åˆ™)
  - list_directory: åˆ—å‡ºç›®å½•å†…å®¹
  - get_file_tree: è·å–é¡¹ç›®ç›®å½•æ ‘

å®‰å…¨æ²™ç®±:
  - è·¯å¾„é™åˆ¶åœ¨ workspace_path å†… (é˜²æ­¢ ../ é€ƒé€¸å’Œç¬¦å·é“¾æ¥é€ƒé€¸)
  - æ•æ„Ÿæ–‡ä»¶é»‘åå• (.env, *.key ç­‰)
  - æ–‡ä»¶è¯»å–è¡Œæ•°ä¸Šé™ (é»˜è®¤ 500 è¡Œ)
  - æœç´¢ç»“æœæ•°é‡ä¸Šé™ (é»˜è®¤ 50 æ¡)
  - åªè¯»: ä¸æä¾›ä»»ä½•å†™å…¥/åˆ é™¤/æ‰§è¡Œå·¥å…·
"""
import asyncio
import logging
import os
import re
import subprocess
import time
from typing import Any, Callable, Dict, List, Optional, Set, Tuple

logger = logging.getLogger(__name__)

# ==================== æƒé™å®šä¹‰ ====================

TOOL_PERMISSIONS = {
    "ask_user",      # å‘ç”¨æˆ·æé—®æ¾„æ¸…
    "read_source",   # è¯»å–æºç æ–‡ä»¶
    "read_config",   # è¯»å–é…ç½®æ–‡ä»¶
    "search",        # å…¨æ–‡æœç´¢
    "tree",          # ç›®å½•æµè§ˆ
}

DEFAULT_PERMISSIONS = set(TOOL_PERMISSIONS)  # é»˜è®¤å…¨éƒ¨å¼€å¯

# ==================== å®‰å…¨é™åˆ¶ ====================

# æ•æ„Ÿæ–‡ä»¶/ç›®å½•é»‘åå•
_SENSITIVE_PATTERNS = {
    # æ–‡ä»¶åç²¾ç¡®åŒ¹é…
    ".env", ".env.local", ".env.production",
    # ç›®å½•
    ".git/objects", ".git/refs", ".git/logs",
    "venv", ".venv", "node_modules", "__pycache__",
    # å®‰å…¨ç›¸å…³
    "id_rsa", "id_ed25519",
}

_SENSITIVE_EXTENSIONS = {
    ".key", ".pem", ".p12", ".pfx", ".jks",
    ".secret", ".credentials",
}

# å…è®¸è¯»å–çš„é…ç½®æ–‡ä»¶ (å³ä½¿åŒ¹é…äº†æ•æ„Ÿæ¨¡å¼)
_CONFIG_ALLOWLIST = {
    "package.json", "tsconfig.json", "vite.config.ts",
    "docker-compose.yml", "Dockerfile", "nginx.conf",
    "requirements.txt", "pyproject.toml", "setup.cfg",
    "CLAUDE.md", "README.md", "TODO.md",
}

# æ–‡ä»¶è¯»å–é™åˆ¶
MAX_READ_LINES = 200
MAX_SEARCH_RESULTS = 30
SEARCH_CONTEXT_LINES = 1
TOOL_TIMEOUT_SECONDS = 10

# ç›®å½•æ ‘é™åˆ¶
MAX_TREE_DEPTH = 4
TREE_SKIP_DIRS = {
    "node_modules", "__pycache__", ".git", ".venv", "venv",
    "dist", ".claude", "studio-data", "data", ".idea", ".vscode",
    ".mypy_cache", ".pytest_cache", ".ruff_cache", "htmlcov",
    ".next", ".nuxt", "build", "target",
}


# ==================== å·¥å…·å®šä¹‰ (OpenAI Function Calling Format) ====================

TOOL_DEFINITIONS: List[Dict[str, Any]] = [
    {
        "type": "function",
        "function": {
            "name": "read_file",
            "description": (
                "è¯»å–é¡¹ç›®ä¸­çš„æ–‡ä»¶å†…å®¹ã€‚æ”¯æŒæŒ‡å®šèµ·å§‹è¡Œå·æ¥ç²¾ç¡®è¯»å–æ„Ÿå…´è¶£çš„ç‰‡æ®µï¼Œ"
                "ä¸å¿…æ¯æ¬¡ä»å¤´è¯»å–æ•´ä¸ªæ–‡ä»¶ã€‚æ¨èç­–ç•¥ï¼šå…ˆç”¨ search_text å®šä½è¡Œå·ï¼Œ"
                "å†ç”¨ start_line è·³è½¬åˆ°ç›®æ ‡ä½ç½®è¯»å–ã€‚å•æ¬¡æœ€å¤šè¿”å› 200 è¡Œã€‚"
                "å°æ–‡ä»¶ï¼ˆ<200è¡Œï¼‰ç›´æ¥ä¸€æ¬¡è¯»å®Œï¼Œä¸è¦æ‹†åˆ†ã€‚"
            ),
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {
                        "type": "string",
                        "description": "ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•çš„æ–‡ä»¶è·¯å¾„ï¼Œä¾‹å¦‚ 'backend/app/games/adventure.py'",
                    },
                    "start_line": {
                        "type": "integer",
                        "description": (
                            "èµ·å§‹è¡Œå· (1-based)ï¼Œé»˜è®¤ä»ç¬¬ 1 è¡Œå¼€å§‹ã€‚"
                            "é…åˆ search_text è¿”å›çš„è¡Œå·ï¼Œå¯ç›´æ¥è·³åˆ°æ„Ÿå…´è¶£çš„ä»£ç ä½ç½®"
                        ),
                    },
                    "end_line": {
                        "type": "integer",
                        "description": "ç»“æŸè¡Œå· (1-based, inclusive)ï¼Œä¸æŒ‡å®šåˆ™ä» start_line å¼€å§‹è¯»å–æœ€å¤š 200 è¡Œ",
                    },
                },
                "required": ["path"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "search_text",
            "description": (
                "åœ¨é¡¹ç›®æ–‡ä»¶ä¸­æœç´¢æ–‡æœ¬æˆ–æ­£åˆ™è¡¨è¾¾å¼ï¼Œè¿”å›åŒ¹é…çš„æ–‡ä»¶è·¯å¾„ã€è¡Œå·å’Œä¸Šä¸‹æ–‡ã€‚"
                "è¿™æ˜¯æœ€é«˜æ•ˆçš„ä»£ç å®šä½å·¥å…·â€”â€”å…ˆæœç´¢ç¡®å®šä½ç½®ï¼Œå†ç”¨ read_file çš„ start_line ç²¾ç¡®è¯»å–ã€‚"
                "åŠ¡å¿…æŒ‡å®š include_pattern ç¼©å°æœç´¢èŒƒå›´ï¼ˆå¦‚ '*.py', '*.vue'ï¼‰ï¼Œ"
                "å¦åˆ™ç»“æœå¯èƒ½è¿‡å¤šã€‚è¿”å›çš„è¡Œå·å¯ç›´æ¥ç”¨äº read_file çš„ start_line å‚æ•°ã€‚"
            ),
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "æœç´¢çš„æ–‡æœ¬æˆ–æ­£åˆ™è¡¨è¾¾å¼",
                    },
                    "is_regex": {
                        "type": "boolean",
                        "description": "æ˜¯å¦ä¸ºæ­£åˆ™è¡¨è¾¾å¼ï¼Œé»˜è®¤ false (ç²¾ç¡®æ–‡æœ¬æœç´¢)",
                        "default": False,
                    },
                    "include_pattern": {
                        "type": "string",
                        "description": (
                            "æ–‡ä»¶å glob è¿‡æ»¤ï¼Œå¦‚ '*.py'ã€'*.vue'ã€'*.ts'ã€‚"
                            "å¼ºçƒˆå»ºè®®å§‹ç»ˆæŒ‡å®šï¼Œé¿å…æœç´¢å…¨éƒ¨æ–‡ä»¶ç±»å‹"
                        ),
                    },
                },
                "required": ["query"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "list_directory",
            "description": (
                "åˆ—å‡ºç›®å½•ä¸‹çš„æ–‡ä»¶å’Œå­ç›®å½•ã€‚ç”¨äºäº†è§£é¡¹ç›®å±€éƒ¨ç»“æ„ã€‚"
                "å»ºè®®å…ˆç”¨ get_file_tree è·å–æ•´ä½“æ¦‚è§ˆï¼Œå†ç”¨æ­¤å·¥å…·æŸ¥çœ‹ç‰¹å®šç›®å½•çš„è¯¦ç»†å†…å®¹ã€‚"
            ),
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {
                        "type": "string",
                        "description": "ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•çš„ç›®å½•è·¯å¾„ï¼Œä¾‹å¦‚ 'backend/app/api'ã€‚ç©ºå­—ç¬¦ä¸²è¡¨ç¤ºé¡¹ç›®æ ¹ç›®å½•ã€‚",
                        "default": "",
                    },
                },
                "required": [],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "get_file_tree",
            "description": (
                "è·å–é¡¹ç›®å®Œæ•´æ–‡ä»¶æ ‘ï¼ˆå¸¦ç¼©è¿›çš„æ ‘çŠ¶ç»“æ„ï¼‰ã€‚"
                "é€‚åˆåœ¨å¯¹è¯å¼€å§‹æ—¶è°ƒç”¨ä¸€æ¬¡ï¼Œå¿«é€Ÿäº†è§£é¡¹ç›®æ•´ä½“ç»“æ„ï¼Œ"
                "å†æ ¹æ®ç»“æ„å†³å®šè¯»å–å“ªäº›æ–‡ä»¶ã€‚è‡ªåŠ¨è¿‡æ»¤ node_modulesã€.git ç­‰æ— å…³ç›®å½•ã€‚"
            ),
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {
                        "type": "string",
                        "description": "å­ç›®å½•è·¯å¾„ (ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•)ï¼Œç©ºå­—ç¬¦ä¸²è¡¨ç¤ºæ•´ä¸ªé¡¹ç›®",
                        "default": "",
                    },
                    "max_depth": {
                        "type": "integer",
                        "description": "ç›®å½•æ ‘æœ€å¤§æ·±åº¦ï¼Œé»˜è®¤ 3",
                        "default": 3,
                    },
                },
                "required": [],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "ask_user",
            "description": (
                "å‘ç”¨æˆ·æå‡ºéœ€è¦æ¾„æ¸…çš„é—®é¢˜ã€‚å½“æè¿°æ¨¡ç³Šã€æœ‰å¤šç§ç†è§£æ–¹å¼ã€"
                "æˆ–ç¼ºå°‘å…³é”®ä¿¡æ¯æ—¶ï¼Œä¸»åŠ¨è°ƒç”¨æ­¤å·¥å…·æé—®ã€‚å¯ä»¥ä¸€æ¬¡æå‡ºå¤šä¸ªé—®é¢˜ã€‚\n\n"
                "## ä½¿ç”¨è§„èŒƒ\n"
                "- æ¯ä¸ªé—®é¢˜é€šè¿‡ type æŒ‡å®š 'single'(å•é€‰) æˆ– 'multi'(å¤šé€‰)\n"
                "- options æ•°ç»„ä¸­çš„é€‰é¡¹æŒ‰æ¨èç¨‹åº¦ä»é«˜åˆ°ä½æ’åˆ—\n"
                "- ä¸ºæœ€æ¨èçš„ 1-2 ä¸ªé€‰é¡¹è®¾ç½® recommended: true\n"
                "- å•é€‰é¢˜æœ€åä¸€ä¸ªé€‰é¡¹é€šå¸¸æ˜¯'å…¶ä»–ï¼ˆè¯·è¯´æ˜ï¼‰'ä¹‹ç±»çš„è‡ªå®šä¹‰é€‰é¡¹ï¼Œé™¤éæ˜¯ä¸¥æ ¼å‡ é€‰ä¸€\n"
                "- ç”¨ context å­—æ®µç®€è¦è¯´æ˜ä¸ºä»€ä¹ˆéœ€è¦æ˜ç¡®è¿™ä¸ªé—®é¢˜\n"
                "- è°ƒç”¨æ­¤å·¥å…·åä½ å¿…é¡»åœæ­¢ï¼Œç­‰å¾…ç”¨æˆ·å›ç­”åå†ç»§ç»­\n"
            ),
            "parameters": {
                "type": "object",
                "properties": {
                    "questions": {
                        "type": "array",
                        "description": "é—®é¢˜åˆ—è¡¨",
                        "items": {
                            "type": "object",
                            "properties": {
                                "question": {
                                    "type": "string",
                                    "description": "é—®é¢˜æ–‡æœ¬",
                                },
                                "type": {
                                    "type": "string",
                                    "enum": ["single", "multi"],
                                    "description": "å•é€‰ single æˆ–å¤šé€‰ multiï¼Œé»˜è®¤ single",
                                },
                                "options": {
                                    "type": "array",
                                    "description": "é€‰é¡¹åˆ—è¡¨ï¼ŒæŒ‰æ¨èç¨‹åº¦ä»é«˜åˆ°ä½æ’åˆ—",
                                    "items": {
                                        "type": "object",
                                        "properties": {
                                            "label": {
                                                "type": "string",
                                                "description": "é€‰é¡¹æ–‡æœ¬",
                                            },
                                            "description": {
                                                "type": "string",
                                                "description": "é€‰é¡¹çš„è¡¥å……è¯´æ˜ï¼ˆå¯é€‰ï¼‰",
                                            },
                                            "recommended": {
                                                "type": "boolean",
                                                "description": "æ˜¯å¦ä¸ºæ¨èé€‰é¡¹",
                                            },
                                        },
                                        "required": ["label"],
                                    },
                                },
                                "context": {
                                    "type": "string",
                                    "description": "ä¸ºä»€ä¹ˆéœ€è¦æ˜ç¡®è¿™ä¸ªé—®é¢˜ï¼ˆç®€è¦è¯´æ˜å¯¹éœ€æ±‚çš„å½±å“ï¼‰",
                                },
                            },
                            "required": ["question"],
                        },
                    },
                },
                "required": ["questions"],
            },
        },
    },
]


def get_tool_definitions(permissions: Optional[Set[str]] = None) -> list:
    """
    è·å–å½“å‰å¯ç”¨çš„å·¥å…·å®šä¹‰åˆ—è¡¨ (æ ¹æ®æƒé™è¿‡æ»¤)

    Args:
        permissions: å…è®¸çš„æƒé™é›†åˆï¼ŒNone è¡¨ç¤ºä½¿ç”¨é»˜è®¤æƒé™ (å…¨éƒ¨å¼€å¯)

    Returns:
        OpenAI tools format åˆ—è¡¨
    """
    perms = permissions or DEFAULT_PERMISSIONS
    tools = []

    for tool_def in TOOL_DEFINITIONS:
        name = tool_def["function"]["name"]
        required_perm = _TOOL_PERMISSION_MAP.get(name)
        if required_perm and required_perm.issubset(perms):
            tools.append(tool_def)

    return tools


# å·¥å…·å â†’ æ‰€éœ€æƒé™æ˜ å°„
_TOOL_PERMISSION_MAP: Dict[str, Set[str]] = {
    "ask_user": {"ask_user"},
    "read_file": {"read_source"},
    "search_text": {"search"},
    "list_directory": {"tree"},
    "get_file_tree": {"tree"},
}


# ==================== è·¯å¾„å®‰å…¨æ£€æŸ¥ ====================

def _validate_path(workspace: str, rel_path: str) -> Tuple[bool, str, str]:
    """
    éªŒè¯è·¯å¾„å®‰å…¨æ€§

    Returns:
        (is_safe, absolute_path, error_message)
    """
    # è§„èŒƒåŒ–è·¯å¾„
    rel_path = rel_path.strip().lstrip("/")

    # é˜»æ­¢ç©ºè·¯å¾„ç”¨äºæ–‡ä»¶æ“ä½œ
    abs_path = os.path.realpath(os.path.join(workspace, rel_path))

    # æ²™ç®±æ£€æŸ¥: å¿…é¡»åœ¨ workspace å†…
    workspace_real = os.path.realpath(workspace)
    if not abs_path.startswith(workspace_real + os.sep) and abs_path != workspace_real:
        return False, abs_path, f"âš ï¸ è·¯å¾„è¶Šç•Œ: '{rel_path}' ä¸åœ¨é¡¹ç›®ç›®å½•å†…"

    return True, abs_path, ""


def _is_sensitive_file(rel_path: str) -> bool:
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åœ¨æ•æ„Ÿé»‘åå•ä¸­"""
    basename = os.path.basename(rel_path)
    _, ext = os.path.splitext(basename)

    # å…è®¸åˆ—è¡¨ä¼˜å…ˆ
    if basename in _CONFIG_ALLOWLIST:
        return False

    # ç²¾ç¡®æ–‡ä»¶ååŒ¹é…
    if basename in _SENSITIVE_PATTERNS:
        return True

    # æ‰©å±•ååŒ¹é…
    if ext.lower() in _SENSITIVE_EXTENSIONS:
        return True

    # è·¯å¾„ä¸­åŒ…å«æ•æ„Ÿç›®å½•
    path_parts = rel_path.replace("\\", "/").split("/")
    for part in path_parts:
        if part in _SENSITIVE_PATTERNS:
            return True

    return False


# ==================== å·¥å…·æ‰§è¡Œå™¨ ====================

async def execute_tool(
    name: str,
    arguments: Dict[str, Any],
    workspace: str,
    permissions: Optional[Set[str]] = None,
) -> str:
    """
    æ‰§è¡ŒæŒ‡å®šå·¥å…·å¹¶è¿”å›ç»“æœæ–‡æœ¬

    Args:
        name: å·¥å…·åç§°
        arguments: å·¥å…·å‚æ•°
        workspace: å·¥ä½œåŒºæ ¹è·¯å¾„
        permissions: å…è®¸çš„æƒé™é›†åˆ

    Returns:
        å·¥å…·æ‰§è¡Œç»“æœ (çº¯æ–‡æœ¬)
    """
    perms = permissions or DEFAULT_PERMISSIONS

    # æƒé™æ£€æŸ¥
    required_perm = _TOOL_PERMISSION_MAP.get(name)
    if required_perm and not required_perm.issubset(perms):
        return f"âš ï¸ å·¥å…· '{name}' å·²è¢«é¡¹ç›®ç®¡ç†å‘˜ç¦ç”¨"

    # æ‰§è¡Œå·¥å…· (å¸¦è¶…æ—¶)
    executor = _TOOL_EXECUTORS.get(name)
    if not executor:
        return f"âš ï¸ æœªçŸ¥å·¥å…·: '{name}'"

    try:
        result = await asyncio.wait_for(
            executor(arguments, workspace),
            timeout=TOOL_TIMEOUT_SECONDS,
        )
        return result
    except asyncio.TimeoutError:
        return f"âš ï¸ å·¥å…· '{name}' æ‰§è¡Œè¶…æ—¶ ({TOOL_TIMEOUT_SECONDS}s)"
    except Exception as e:
        logger.exception(f"å·¥å…· {name} æ‰§è¡Œå¤±è´¥")
        return f"âš ï¸ å·¥å…·æ‰§è¡Œå¤±è´¥: {str(e)}"


# ==================== å…·ä½“å·¥å…·å®ç° ====================

async def _tool_read_file(args: Dict[str, Any], workspace: str) -> str:
    """è¯»å–æ–‡ä»¶å†…å®¹"""
    path = args.get("path", "")
    start_line = args.get("start_line", 1)
    end_line = args.get("end_line")

    if not path:
        return "âš ï¸ è¯·æŒ‡å®šæ–‡ä»¶è·¯å¾„"

    # è·¯å¾„å®‰å…¨æ£€æŸ¥
    is_safe, abs_path, error = _validate_path(workspace, path)
    if not is_safe:
        return error

    # æ•æ„Ÿæ–‡ä»¶æ£€æŸ¥
    if _is_sensitive_file(path):
        return f"âš ï¸ æ— æ³•è¯»å–æ•æ„Ÿæ–‡ä»¶: '{path}'"

    if not os.path.exists(abs_path):
        return f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: '{path}'"

    if not os.path.isfile(abs_path):
        return f"âš ï¸ '{path}' ä¸æ˜¯æ–‡ä»¶ (å¯èƒ½æ˜¯ç›®å½•ï¼Œè¯·ä½¿ç”¨ list_directory)"

    # æ£€æŸ¥æ–‡ä»¶å¤§å° (è·³è¿‡è¿‡å¤§çš„äºŒè¿›åˆ¶æ–‡ä»¶)
    file_size = os.path.getsize(abs_path)
    if file_size > 1024 * 1024:  # 1MB
        return f"âš ï¸ æ–‡ä»¶è¿‡å¤§ ({file_size / 1024:.0f}KB)ï¼Œè¯·æŒ‡å®šè¡ŒèŒƒå›´è¯»å–"

    try:
        with open(abs_path, "r", encoding="utf-8", errors="replace") as f:
            lines = f.readlines()
    except UnicodeDecodeError:
        return f"âš ï¸ '{path}' æ˜¯äºŒè¿›åˆ¶æ–‡ä»¶ï¼Œæ— æ³•è¯»å–"

    total_lines = len(lines)

    # å¤„ç†è¡ŒèŒƒå›´
    start = max(1, start_line or 1)
    end = min(total_lines, end_line or (start + MAX_READ_LINES - 1))

    # æœ€å¤šè¯»å– MAX_READ_LINES è¡Œ
    if end - start + 1 > MAX_READ_LINES:
        end = start + MAX_READ_LINES - 1

    selected = lines[start - 1:end]
    content = "".join(selected)

    # æ„å»ºç»“æœå¤´ä¿¡æ¯
    header = f"ğŸ“„ {path} (è¡Œ {start}-{end}, å…± {total_lines} è¡Œ)"
    if end < total_lines:
        header += f" [æˆªæ–­: ä½¿ç”¨ start_line/end_line æŸ¥çœ‹æ›´å¤š]"

    return f"{header}\n```\n{content}```"


async def _tool_search_text(args: Dict[str, Any], workspace: str) -> str:
    """å…¨æ–‡æœç´¢"""
    query = args.get("query", "")
    is_regex = args.get("is_regex", False)
    include_pattern = args.get("include_pattern", "")

    if not query:
        return "âš ï¸ è¯·æŒ‡å®šæœç´¢å†…å®¹"

    # æ„å»º grep å‘½ä»¤
    cmd = ["grep", "-rn", "--color=never"]

    if is_regex:
        cmd.append("-E")
    else:
        cmd.append("-F")

    # ä¸Šä¸‹æ–‡è¡Œ
    cmd.extend(["-B", str(SEARCH_CONTEXT_LINES), "-A", str(SEARCH_CONTEXT_LINES)])

    # æœ€å¤§ç»“æœæ•°
    cmd.extend(["-m", str(MAX_SEARCH_RESULTS)])

    # æ’é™¤ç›®å½•
    for skip_dir in TREE_SKIP_DIRS:
        cmd.extend(["--exclude-dir", skip_dir])

    # æ’é™¤æ•æ„Ÿæ–‡ä»¶
    for ext in _SENSITIVE_EXTENSIONS:
        cmd.extend(["--exclude", f"*{ext}"])
    cmd.extend(["--exclude", ".env*"])

    # åŒ…å«æ¨¡å¼ (ä¿®æ­£: grep --include ä¸æ”¯æŒ ** æˆ–è·¯å¾„, åªæ”¯æŒæ–‡ä»¶å glob)
    if include_pattern:
        # å»æ‰è·¯å¾„å‰ç¼€ (å¦‚ **/*.py â†’ *.py, src/**/*.ts â†’ *.ts)
        clean_pattern = include_pattern
        if '/' in clean_pattern:
            clean_pattern = clean_pattern.rsplit('/', 1)[-1]
        if not clean_pattern or clean_pattern == '**':
            clean_pattern = '*'
        cmd.extend(["--include", clean_pattern])

    cmd.append(query)
    cmd.append(".")

    try:
        proc = await asyncio.create_subprocess_exec(
            *cmd,
            cwd=workspace,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
        )
        stdout, stderr = await asyncio.wait_for(proc.communicate(), timeout=TOOL_TIMEOUT_SECONDS)
        output = stdout.decode("utf-8", errors="replace").strip()

        if not output:
            return f"ğŸ” æœªæ‰¾åˆ°åŒ¹é…: '{query}'"

        # æ¸…ç†è·¯å¾„ (å»æ‰ ./ å‰ç¼€)
        output = output.replace("\n./", "\n").lstrip("./")

        # é™åˆ¶è¾“å‡ºé•¿åº¦ (è¡Œæ•° + å­—ç¬¦æ•°åŒé‡é™åˆ¶)
        MAX_OUTPUT_LINES = 120
        MAX_OUTPUT_CHARS = 6000
        lines = output.split("\n")
        if len(lines) > MAX_OUTPUT_LINES:
            output = "\n".join(lines[:MAX_OUTPUT_LINES])
            output += f"\n\n... (ç»“æœè¿‡å¤šï¼Œå·²æˆªæ–­è‡³ {MAX_OUTPUT_LINES} è¡Œã€‚è¯·ä½¿ç”¨ include_pattern ç¼©å°èŒƒå›´)"
        if len(output) > MAX_OUTPUT_CHARS:
            output = output[:MAX_OUTPUT_CHARS]
            output += f"\n\n... (è¾“å‡ºè¿‡é•¿ï¼Œå·²æˆªæ–­è‡³ {MAX_OUTPUT_CHARS} å­—ç¬¦ã€‚è¯·ç¼©å°æœç´¢èŒƒå›´æˆ–æŒ‡å®š include_pattern)"

        pattern_desc = f"æ­£åˆ™ '{query}'" if is_regex else f"'{query}'"
        scope = f" (èŒƒå›´: {include_pattern})" if include_pattern else ""
        return f"ğŸ” æœç´¢ {pattern_desc}{scope}:\n\n{output}"

    except FileNotFoundError:
        # grep ä¸å¯ç”¨ï¼Œé€€å›åˆ° Python å®ç°
        return await _python_search(query, is_regex, include_pattern, workspace)


async def _python_search(
    query: str, is_regex: bool, include_pattern: str, workspace: str,
) -> str:
    """Python å¤‡ç”¨æœç´¢å®ç° (grep ä¸å¯ç”¨æ—¶)"""
    import fnmatch

    if is_regex:
        try:
            pattern = re.compile(query, re.IGNORECASE)
        except re.error as e:
            return f"âš ï¸ æ— æ•ˆçš„æ­£åˆ™è¡¨è¾¾å¼: {e}"
    else:
        pattern = None

    results: List[str] = []
    count = 0

    for root, dirs, files in os.walk(workspace):
        # è·³è¿‡æ’é™¤ç›®å½•
        dirs[:] = [d for d in dirs if d not in TREE_SKIP_DIRS]

        for fname in files:
            if count >= MAX_SEARCH_RESULTS:
                break

            # æ•æ„Ÿæ–‡ä»¶æ£€æŸ¥
            rel_path = os.path.relpath(os.path.join(root, fname), workspace)
            if _is_sensitive_file(rel_path):
                continue

            # include_pattern è¿‡æ»¤
            if include_pattern and not fnmatch.fnmatch(fname, include_pattern):
                continue

            try:
                with open(os.path.join(root, fname), "r", encoding="utf-8", errors="replace") as f:
                    file_lines = f.readlines()
            except Exception:
                continue

            for i, line in enumerate(file_lines):
                if count >= MAX_SEARCH_RESULTS:
                    break

                matched = False
                if pattern:
                    matched = bool(pattern.search(line))
                else:
                    matched = query.lower() in line.lower()

                if matched:
                    count += 1
                    line_num = i + 1
                    # ä¸Šä¸‹æ–‡
                    ctx_start = max(0, i - SEARCH_CONTEXT_LINES)
                    ctx_end = min(len(file_lines), i + SEARCH_CONTEXT_LINES + 1)
                    ctx = ""
                    for j in range(ctx_start, ctx_end):
                        prefix = ">" if j == i else " "
                        ctx += f"{prefix} {j+1}: {file_lines[j]}"
                    results.append(f"{rel_path}:{line_num}\n{ctx}")

    if not results:
        return f"ğŸ” æœªæ‰¾åˆ°åŒ¹é…: '{query}'"

    output = "\n---\n".join(results)
    truncated = f"\n\n... (å·²è¾¾åˆ° {MAX_SEARCH_RESULTS} æ¡ä¸Šé™)" if count >= MAX_SEARCH_RESULTS else ""
    return f"ğŸ” æœç´¢ '{query}' æ‰¾åˆ° {count} ä¸ªåŒ¹é…:\n\n{output}{truncated}"


async def _tool_list_directory(args: Dict[str, Any], workspace: str) -> str:
    """åˆ—å‡ºç›®å½•å†…å®¹"""
    path = args.get("path", "")

    # è·¯å¾„å®‰å…¨æ£€æŸ¥
    is_safe, abs_path, error = _validate_path(workspace, path or ".")
    if not is_safe:
        return error

    if not os.path.exists(abs_path):
        return f"âš ï¸ ç›®å½•ä¸å­˜åœ¨: '{path}'"

    if not os.path.isdir(abs_path):
        return f"âš ï¸ '{path}' ä¸æ˜¯ç›®å½• (è¯·ä½¿ç”¨ read_file è¯»å–æ–‡ä»¶)"

    try:
        entries = sorted(os.listdir(abs_path))
    except PermissionError:
        return f"âš ï¸ æ— æƒè®¿é—®: '{path}'"

    # è¿‡æ»¤éšè—å’Œå¿½ç•¥çš„ç›®å½•
    entries = [e for e in entries if e not in TREE_SKIP_DIRS and not e.startswith("__pycache__")]

    dirs = []
    files = []
    for entry in entries:
        full = os.path.join(abs_path, entry)
        if os.path.isdir(full):
            # è®¡ç®—å­é¡¹æ•°é‡
            try:
                sub_count = len(os.listdir(full))
            except Exception:
                sub_count = 0
            dirs.append(f"ğŸ“ {entry}/ ({sub_count} items)")
        else:
            size = os.path.getsize(full)
            size_str = f"{size}B" if size < 1024 else f"{size / 1024:.1f}KB" if size < 1048576 else f"{size / 1048576:.1f}MB"
            files.append(f"ğŸ“„ {entry} ({size_str})")

    display_path = path or "."
    result = f"ğŸ“‚ {display_path}/\n"
    result += "\n".join(dirs + files)

    if not dirs and not files:
        result += "(ç©ºç›®å½•)"

    return result


async def _tool_get_file_tree(args: Dict[str, Any], workspace: str) -> str:
    """è·å–ç›®å½•æ ‘"""
    path = args.get("path", "")
    max_depth = min(args.get("max_depth", 3), MAX_TREE_DEPTH)

    # è·¯å¾„å®‰å…¨æ£€æŸ¥
    target = os.path.join(workspace, path) if path else workspace
    is_safe, abs_path, error = _validate_path(workspace, path or ".")
    if not is_safe:
        return error

    if not os.path.exists(abs_path):
        return f"âš ï¸ è·¯å¾„ä¸å­˜åœ¨: '{path}'"

    if not os.path.isdir(abs_path):
        return f"âš ï¸ '{path}' ä¸æ˜¯ç›®å½•"

    tree = _build_tree(abs_path, max_depth)
    display_path = path or "."
    return f"ğŸŒ³ {display_path}/ ç›®å½•æ ‘ (æ·±åº¦: {max_depth}):\n\n{tree}"


def _build_tree(path: str, max_depth: int, prefix: str = "", depth: int = 0) -> str:
    """é€’å½’æ„å»ºç›®å½•æ ‘"""
    if depth >= max_depth:
        return ""

    try:
        entries = sorted(os.listdir(path))
    except PermissionError:
        return f"{prefix}(æ— æƒé™è®¿é—®)\n"

    # è¿‡æ»¤
    entries = [e for e in entries if e not in TREE_SKIP_DIRS and not e.startswith(".")]

    lines = []
    for i, entry in enumerate(entries):
        is_last = i == len(entries) - 1
        connector = "â””â”€â”€ " if is_last else "â”œâ”€â”€ "
        full_path = os.path.join(path, entry)

        if os.path.isdir(full_path):
            lines.append(f"{prefix}{connector}{entry}/")
            extension = "    " if is_last else "â”‚   "
            subtree = _build_tree(full_path, max_depth, prefix + extension, depth + 1)
            if subtree:
                lines.append(subtree)
        else:
            lines.append(f"{prefix}{connector}{entry}")

    return "\n".join(lines)


async def _tool_ask_user(args: Dict[str, Any], workspace: str) -> str:
    """å‘ç”¨æˆ·æå‡ºéœ€æ±‚æ¾„æ¸…é—®é¢˜ (ç»“æœç›´æ¥é€ä¼ ç»™å‰ç«¯æ¸²æŸ“)"""
    questions = args.get("questions", [])
    if not questions:
        return "âš ï¸ è¯·è‡³å°‘æå‡ºä¸€ä¸ªé—®é¢˜"
    count = len(questions)
    return f"âœ… å·²å‘ç”¨æˆ·å±•ç¤º {count} ä¸ªé—®é¢˜ï¼Œè¯·ç­‰å¾…ç”¨æˆ·å›ç­”åå†ç»§ç»­è®¨è®ºã€‚ä¸è¦è‡ªè¡Œå‡è®¾ç­”æ¡ˆã€‚"


# å·¥å…·æ‰§è¡Œå™¨æ˜ å°„
_TOOL_EXECUTORS: Dict[str, Callable] = {
    "read_file": _tool_read_file,
    "search_text": _tool_search_text,
    "list_directory": _tool_list_directory,
    "get_file_tree": _tool_get_file_tree,
    "ask_user": _tool_ask_user,
}
